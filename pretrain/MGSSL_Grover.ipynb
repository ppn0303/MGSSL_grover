{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ababd22-105f-4808-9bb3-3f1c0cb7ba2e",
   "metadata": {},
   "source": [
    "# main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b2792b6-d7a5-4da2-aaef-66ccefb071bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import math, random, sys\n",
    "import numpy as np\n",
    "from optparse import OptionParser\n",
    "from gnn_model import GNN, GNN_grover\n",
    "\n",
    "sys.path.append('./util/')\n",
    "\n",
    "from mol_tree import *\n",
    "from nnutils import *\n",
    "from datautils import *\n",
    "from motif_generation import *\n",
    "\n",
    "import rdkit\n",
    "\n",
    "# add for grover\n",
    "import os, time\n",
    "import wandb\n",
    "from grover.topology.mol_tree import *\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb927c83-2614-419a-a409-e6f34df71450",
   "metadata": {},
   "outputs": [],
   "source": [
    "lg = rdkit.RDLogger.logger()\n",
    "lg.setLevel(rdkit.RDLogger.CRITICAL)\n",
    "# 치명적 오류가 발생되면 로그기록해라\n",
    "\n",
    "def group_node_rep(node_rep, batch_index, batch_size):\n",
    "    group = []\n",
    "    count = 0\n",
    "    for i in range(batch_size):\n",
    "        num = sum(batch_index == i)\n",
    "        group.append(node_rep[count:count + num])\t\t# count += num번째 node의 표현을 그룹에 더해라\n",
    "        count += num\n",
    "    return group\t\t\t\t\t\t# 최종 그룹을 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108da478-3fd0-4196-8d7c-b9145911831b",
   "metadata": {},
   "source": [
    "## args.parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ee8f6d5-3ae8-474d-9e42-bb170b3b49bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch implementation of pre-training of graph neural networks')\n",
    "parser.add_argument('--device', type=int, default=0,\n",
    "                    help='which gpu to use if any (default: 0)')\n",
    "parser.add_argument('--batch_size', type=int, default=32,\n",
    "                    help='input batch size for training (default: 32)')\n",
    "parser.add_argument('--epochs', type=int, default=100,\n",
    "                    help='number of epochs to train (default: 100)')\n",
    "parser.add_argument('--lr', type=float, default=0.001,\n",
    "                    help='learning rate (default: 0.001)')\n",
    "parser.add_argument('--decay', type=float, default=0,\n",
    "                    help='weight decay (default: 0)')\n",
    "parser.add_argument('--num_layer', type=int, default=5,\n",
    "                    help='number of GNN message passing layers (default: 5).')\n",
    "parser.add_argument('--emb_dim', type=int, default=300,\n",
    "                    help='embedding dimensions (default: 300)')\n",
    "parser.add_argument('--dropout_ratio', type=float, default=0.2,\n",
    "                    help='dropout ratio (default: 0.2)')\n",
    "parser.add_argument('--graph_pooling', type=str, default=\"mean\",\n",
    "                    help='graph level pooling (sum, mean, max, set2set, attention)')\n",
    "parser.add_argument('--JK', type=str, default=\"last\",\n",
    "                    help='how the node features across layers are combined. last, sum, max or concat')\n",
    "parser.add_argument('--dataset', type=str, default='./data/merge_0',\n",
    "                    help='root directory of dataset. For now, only classification.')\n",
    "parser.add_argument('--gnn_type', type=str, default=\"gin\")\n",
    "parser.add_argument('--input_model_file', type=str, default=\"\", help='filename to read the model (if there is any)')\n",
    "parser.add_argument('--output_path', type=str, default='./saved_model/grover',\n",
    "                    help='filename to output the pre-trained model')\n",
    "parser.add_argument('--num_workers', type=int, default=0, help='number of workers for dataset loading')   #원래는 8이었음 오류로 0으로 바꿈\n",
    "parser.add_argument(\"--hidden_size\", type=int, default=300, help='hidden size')\n",
    "parser.add_argument(\"--vocab\", type=str, default='./data/merge/clique.txt', help='vocab path')\n",
    "parser.add_argument('--order', type=str, default=\"bfs\",\n",
    "                    help='motif tree generation order (bfs or dfs)')\n",
    "#for wandb\n",
    "parser.add_argument('--wandb', action='store_true', default=False, help='add wandb log')\n",
    "parser.add_argument('--wandb_name', type=str, default = 'MGSSL_Grover', help='wandb name')\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c500367-8fab-4ff5-ad22-0e0ee8ac08b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(JK='last', batch_size=32, dataset='./data/merge_0', decay=0, device=0, dropout_ratio=0.2, emb_dim=300, epochs=100, gnn_type='gin', graph_pooling='mean', hidden_size=300, input_model_file='', lr=0.001, num_layer=5, num_workers=0, order='bfs', output_path='./saved_model/grover', vocab='./data/merge/clique.txt', wandb=False, wandb_name='MGSSL_Grover')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76838e43-64d5-48c1-84d7-5fac87e34f2d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# change features list\n",
    "- 나와야될 형태는 atom_feature, edge_index, edge_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "721b93a5-9397-4bd3-b395-ad2459fb0adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from mol_tree import MolTree\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem import AllChem\n",
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84f0894a-b183-47a9-b6ab-b8bc5b7bd0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "from typing import List, Tuple, Union\n",
    "import pickle\n",
    "\n",
    "ATOM_FEATURES = {\n",
    "    'atomic_num': list(range(120)),\n",
    "    'degree': [0, 1, 2, 3, 4, 5],\n",
    "    'formal_charge': [-1, -2, 1, 2, 0],\n",
    "    'chiral_tag': [0, 1, 2, 3],\n",
    "    'num_Hs': [0, 1, 2, 3, 4],\n",
    "    'hybridization': [\n",
    "        Chem.rdchem.HybridizationType.SP,\n",
    "        Chem.rdchem.HybridizationType.SP2,\n",
    "        Chem.rdchem.HybridizationType.SP3,\n",
    "        Chem.rdchem.HybridizationType.SP3D,\n",
    "        Chem.rdchem.HybridizationType.SP3D2\n",
    "    ],\n",
    "}\n",
    "atom_fdim = 151\n",
    "bond_fdim = 165"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72fc333-8a1e-4b17-88ab-a69ddbecd0c4",
   "metadata": {},
   "source": [
    "##  함수 및 사전설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91adb922-a822-47ba-8e75-18d35657b96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onek_encoding_unk(value: int, choices: List[int]) -> List[int]:\n",
    "    \"\"\"\n",
    "    Creates a one-hot encoding.\n",
    "\n",
    "    :param value: The value for which the encoding should be one.\n",
    "    :param choices: A list of possible values.\n",
    "    :return: A one-hot encoding of the value in a list of length len(choices) + 1.\n",
    "    If value is not in the list of choices, then the final element in the encoding is 1.\n",
    "    \"\"\"\n",
    "    encoding = [0] * (len(choices) + 1)\n",
    "    if min(choices) < 0:\n",
    "        index = value\n",
    "    else:\n",
    "        index = choices.index(value) if value in choices else -1\n",
    "    encoding[index] = 1\n",
    "\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42a96638-7653-4b1e-a3ba-8aed8feffdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def atom_features(atom: Chem.rdchem.Atom, hydrogen_acceptor_match, hydrogen_donor_match, acidic_match, basic_match, ring_info) -> List[Union[bool, int, float]]:\n",
    "    \"\"\"\n",
    "    Builds a feature vector for an atom.\n",
    "\n",
    "    :param atom: An RDKit atom.\n",
    "    :param functional_groups: A k-hot vector indicating the functional groups the atom belongs to.\n",
    "    :return: A list containing the atom features.\n",
    "    \"\"\"\n",
    "    features = onek_encoding_unk(atom.GetAtomicNum() - 1, ATOM_FEATURES['atomic_num']) + \\\n",
    "               onek_encoding_unk(atom.GetTotalDegree(), ATOM_FEATURES['degree']) + \\\n",
    "               onek_encoding_unk(atom.GetFormalCharge(), ATOM_FEATURES['formal_charge']) + \\\n",
    "               onek_encoding_unk(int(atom.GetChiralTag()), ATOM_FEATURES['chiral_tag']) + \\\n",
    "               onek_encoding_unk(int(atom.GetTotalNumHs()), ATOM_FEATURES['num_Hs']) + \\\n",
    "               onek_encoding_unk(int(atom.GetHybridization()), ATOM_FEATURES['hybridization']) + \\\n",
    "               [1 if atom.GetIsAromatic() else 0] + \\\n",
    "               [atom.GetMass() * 0.01]\n",
    "    atom_idx = atom.GetIdx()\n",
    "    features = features + \\\n",
    "               onek_encoding_unk(atom.GetImplicitValence(), [0, 1, 2, 3, 4, 5, 6]) + \\\n",
    "               [atom_idx in hydrogen_acceptor_match] + \\\n",
    "               [atom_idx in hydrogen_donor_match] + \\\n",
    "               [atom_idx in acidic_match] + \\\n",
    "               [atom_idx in basic_match] + \\\n",
    "               [ring_info.IsAtomInRingOfSize(atom_idx, 3),\n",
    "                ring_info.IsAtomInRingOfSize(atom_idx, 4),\n",
    "                ring_info.IsAtomInRingOfSize(atom_idx, 5),\n",
    "                ring_info.IsAtomInRingOfSize(atom_idx, 6),\n",
    "                ring_info.IsAtomInRingOfSize(atom_idx, 7),\n",
    "                ring_info.IsAtomInRingOfSize(atom_idx, 8)]\n",
    "    return features\n",
    "\n",
    "def bond_features(bond: Chem.rdchem.Bond\n",
    "                  ) -> List[Union[bool, int, float]]:\n",
    "    \"\"\"\n",
    "    Builds a feature vector for a bond.\n",
    "\n",
    "    :param bond: A RDKit bond.\n",
    "    :return: A list containing the bond features.\n",
    "    \"\"\"\n",
    "\n",
    "    if bond is None:\n",
    "        fbond = [1] + [0] * (BOND_FDIM - 1)\n",
    "    else:\n",
    "        bt = bond.GetBondType()\n",
    "        fbond = [\n",
    "            0,  # bond is not None\n",
    "            bt == Chem.rdchem.BondType.SINGLE,\n",
    "            bt == Chem.rdchem.BondType.DOUBLE,\n",
    "            bt == Chem.rdchem.BondType.TRIPLE,\n",
    "            bt == Chem.rdchem.BondType.AROMATIC,\n",
    "            (bond.GetIsConjugated() if bt is not None else 0),\n",
    "            (bond.IsInRing() if bt is not None else 0)\n",
    "        ]\n",
    "        fbond += onek_encoding_unk(int(bond.GetStereo()), list(range(6)))\n",
    "    return fbond"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b924d079-5540-4de2-975d-360f50e1a65f",
   "metadata": {},
   "source": [
    "atom_features_list = []\n",
    "for atom in mol.GetAtoms():\n",
    "    atom_idx = atom.GetIdx()\n",
    "    atom_feature = \n",
    "    # 원자 번호로 1~100을 0~99로 할당(100)\n",
    "    [GROVER_FEATURES['atomic_num'].index(atom.GetAtomicNum() - 1)] + \\\n",
    "    # -2~2까지 5개의 수로 되어 있는 것에 할당(5)\n",
    "    [GROVER_FEATURES['formal_charge'].index(atom.GetChiralTag())] + \\\n",
    "    # 0~3까지 4개의 수(4)\n",
    "    [GROVER_FEATURES['chiral_tag'].index(atom.GetChiralTag())] + \\\n",
    "    # 0~4까지 5개의 수\n",
    "    [GROVER_FEATURES['num_Hs'].index(atom.GetTotalNumHs())] + \\\n",
    "    # 0.01~2.5정도까지의 분자량. 이거 어케하지?\n",
    "    [atom.GetMass() * 0.01] + \\\n",
    "    # 방향성족에 있는지를 0,1으로\n",
    "    [1 if atom.GetIsAromatic() else 0] + \\\n",
    "    # 혼성궤도 결합여부? 5개의 경우\n",
    "    [GROVER_FEATURES['hybridization'].index(atom.GetHybridization())] + \\\n",
    "    # degree of the atom in the molecule including Hs, 논문에 없던 것임. 0~4까지로 동서남북 의미하나?\n",
    "    [GROVER_FEATURES['degree'].index(atom.GetTotalDegree())] + \\\n",
    "    # number of implicit Hs on the atom\n",
    "    [GROVER_FEATURES['implicit'].index(atom.GetImplicitValence())] + \\\n",
    "    # hydrogen_acceptor인지 여부 이진 분류\n",
    "    [int(atom_idx in hydrogen_acceptor_match)] + \\\n",
    "    # hydrogen_donor인지 여부 이진 분류\n",
    "    [int(atom_idx in hydrogen_donor_match)] + \\\n",
    "    # hydrogen_donor인지 여부 이진 분류\n",
    "    [int(atom_idx in acidic_match)] + \\\n",
    "    # 산성 원자인지 여부\n",
    "    [int(atom_idx in basic_match)] + \\\n",
    "    # 몇개짜리 방향성 족에 있는 원자냐로 0(방향성족X)~6(최대 8개 고리)로 7개의 경우\n",
    "    [isatominringofsize(atom_idx)]\n",
    "    atom_features_list.append(atom_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1f73c75-1517-44ee-b5dc-e36051055dd6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MAX_ATOMIC_NUM' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-75985badb13c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m ATOM_FEATURES = {\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;34m'atomic_num'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_ATOMIC_NUM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;34m'degree'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m'formal_charge'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m'chiral_tag'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MAX_ATOMIC_NUM' is not defined"
     ]
    }
   ],
   "source": [
    "ATOM_FEATURES = {\n",
    "    'atomic_num': list(range(MAX_ATOMIC_NUM)),\n",
    "    'degree': [0, 1, 2, 3, 4, 5],\n",
    "    'formal_charge': [-1, -2, 1, 2, 0],\n",
    "    'chiral_tag': [0, 1, 2, 3],\n",
    "    'num_Hs': [0, 1, 2, 3, 4],\n",
    "    'hybridization': [\n",
    "        Chem.rdchem.HybridizationType.SP,\n",
    "        Chem.rdchem.HybridizationType.SP2,\n",
    "        Chem.rdchem.HybridizationType.SP3,\n",
    "        Chem.rdchem.HybridizationType.SP3D,\n",
    "        Chem.rdchem.HybridizationType.SP3D2\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f445934a-5a2a-4ec7-aefe-963da6a82d10",
   "metadata": {},
   "source": [
    "## mol_to_graph_data_obj_grover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61608b85-7d24-45e2-a286-07cbfb794eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mol_to_graph_data_obj_grover(mol):\n",
    "    mol = Chem.MolFromSmiles(mol)\n",
    "    hydrogen_donor = Chem.MolFromSmarts(\"[$([N;!H0;v3,v4&+1]),$([O,S;H1;+0]),n&H1&+0]\")\n",
    "    hydrogen_acceptor = Chem.MolFromSmarts(\n",
    "        \"[$([O,S;H1;v2;!$(*-*=[O,N,P,S])]),$([O,S;H0;v2]),$([O,S;-]),$([N;v3;!$(N-*=[O,N,P,S])]),\"\n",
    "        \"n&H0&+0,$([o,s;+0;!$([o,s]:n);!$([o,s]:c:n)])]\")\n",
    "    acidic = Chem.MolFromSmarts(\"[$([C,S](=[O,S,P])-[O;H1,-1])]\")\n",
    "    basic = Chem.MolFromSmarts(\n",
    "        \"[#7;+,$([N;H2&+0][$([C,a]);!$([C,a](=O))]),$([N;H1&+0]([$([C,a]);!$([C,a](=O))])[$([C,a]);\"\n",
    "        \"!$([C,a](=O))]),$([N;H0&+0]([C;!$(C(=O))])([C;!$(C(=O))])[C;!$(C(=O))])]\")\n",
    "\n",
    "    hydrogen_donor_match = sum(mol.GetSubstructMatches(hydrogen_donor), ())\n",
    "    hydrogen_acceptor_match = sum(mol.GetSubstructMatches(hydrogen_acceptor), ())\n",
    "    acidic_match = sum(mol.GetSubstructMatches(acidic), ())\n",
    "    basic_match = sum(mol.GetSubstructMatches(basic), ())\n",
    "    ring_info = mol.GetRingInfo()\n",
    "\n",
    "    n_atoms = mol.GetNumAtoms()\n",
    "    \n",
    "    f_atoms = []\n",
    "    for _, atom in enumerate(mol.GetAtoms()):\n",
    "        f_atoms.append(atom_features(atom, hydrogen_donor_match, hydrogen_acceptor_match, acidic_match, basic_match, ring_info))\n",
    "    f_atoms = [f_atoms[i] for i in range(n_atoms)]\n",
    "    \n",
    "    f_bonds = []\n",
    "    bond_list = []\n",
    "    for a1 in range(n_atoms):\n",
    "        for a2 in range(a1 + 1, n_atoms):\n",
    "            bond = mol.GetBondBetweenAtoms(a1, a2)\n",
    "\n",
    "            if bond is None:\n",
    "                continue\n",
    "\n",
    "            f_bond = bond_features(bond)\n",
    "\n",
    "            # Always treat the bond as directed.\n",
    "            f_bonds.append(f_atoms[a1] + f_bond)\n",
    "            bond_list.append([a1, a2])\n",
    "            f_bonds.append(f_atoms[a2] + f_bond)\n",
    "            bond_list.append([a2, a1])\n",
    "    \n",
    "    data = [f_atoms, bond_list, f_bonds]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "432e0891-9bcc-4d70-b753-cc3185e8cf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mol_to_graph_data_obj_grover('C=CCOc1cccnc1C(=O)NC[C@H]1CC[C@@H](C(=O)N(C)C)O1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfc9283-8474-44b6-b915-7c49fa42f346",
   "metadata": {},
   "source": [
    "### 세부실행 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5aa1bbf-2fd2-4ec2-a3f7-c4aadbd8408d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mol = Chem.MolFromSmiles('C=CCOc1cccnc1C(=O)NC[C@H]1CC[C@@H](C(=O)N(C)C)O1')\n",
    "# 이건 mol단계에 인식되게 넣어야한다.\n",
    "hydrogen_donor = Chem.MolFromSmarts(\"[$([N;!H0;v3,v4&+1]),$([O,S;H1;+0]),n&H1&+0]\")\n",
    "hydrogen_acceptor = Chem.MolFromSmarts(\n",
    "    \"[$([O,S;H1;v2;!$(*-*=[O,N,P,S])]),$([O,S;H0;v2]),$([O,S;-]),$([N;v3;!$(N-*=[O,N,P,S])]),\"\n",
    "    \"n&H0&+0,$([o,s;+0;!$([o,s]:n);!$([o,s]:c:n)])]\")\n",
    "acidic = Chem.MolFromSmarts(\"[$([C,S](=[O,S,P])-[O;H1,-1])]\")\n",
    "basic = Chem.MolFromSmarts(\n",
    "    \"[#7;+,$([N;H2&+0][$([C,a]);!$([C,a](=O))]),$([N;H1&+0]([$([C,a]);!$([C,a](=O))])[$([C,a]);\"\n",
    "    \"!$([C,a](=O))]),$([N;H0&+0]([C;!$(C(=O))])([C;!$(C(=O))])[C;!$(C(=O))])]\")\n",
    "\n",
    "hydrogen_donor_match = sum(mol.GetSubstructMatches(hydrogen_donor), ())\n",
    "hydrogen_acceptor_match = sum(mol.GetSubstructMatches(hydrogen_acceptor), ())\n",
    "acidic_match = sum(mol.GetSubstructMatches(acidic), ())\n",
    "basic_match = sum(mol.GetSubstructMatches(basic), ())\n",
    "ring_info = mol.GetRingInfo()\n",
    "\n",
    "n_atoms = mol.GetNumAtoms()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5ff3f5-e461-4fa3-9162-db38b9c65173",
   "metadata": {},
   "source": [
    "### atom feature 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98f9b89c-1836-48d3-8778-e9f57b12d937",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "atom_features() missing 5 required positional arguments: 'hydrogen_acceptor_match', 'hydrogen_donor_match', 'acidic_match', 'basic_match', and 'ring_info'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-5961eeff5093>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mf_atoms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matom\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetAtoms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mf_atoms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matom_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mf_atoms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf_atoms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_atoms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# f_atoms는 atom개수 x 151\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: atom_features() missing 5 required positional arguments: 'hydrogen_acceptor_match', 'hydrogen_donor_match', 'acidic_match', 'basic_match', and 'ring_info'"
     ]
    }
   ],
   "source": [
    "f_atoms = []\n",
    "for _, atom in enumerate(mol.GetAtoms()):\n",
    "    f_atoms.append(atom_features(atom))\n",
    "f_atoms = [f_atoms[i] for i in range(n_atoms)]\n",
    "# f_atoms는 atom개수 x 151"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2659c62-a5be-433c-b1bf-590c79272646",
   "metadata": {},
   "source": [
    "### bond feature 생성으로 atom과 이어서 있어야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2545c9d7-2702-4d00-a75b-ebb5ec164025",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_bonds = []\n",
    "bond_list = []\n",
    "for a1 in range(n_atoms):\n",
    "    for a2 in range(a1 + 1, n_atoms):\n",
    "        bond = mol.GetBondBetweenAtoms(a1, a2)\n",
    "\n",
    "        if bond is None:\n",
    "            continue\n",
    "\n",
    "        f_bond = bond_features(bond)\n",
    "\n",
    "        # Always treat the bond as directed.\n",
    "        f_bonds.append(f_atoms[a1] + f_bond)\n",
    "        bond_list.append([a1, a2])\n",
    "        f_bonds.append(f_atoms[a2] + f_bond)\n",
    "        bond_list.append([a2, a1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f03a359-5628-491e-8c0a-2bd2e225a13d",
   "metadata": {},
   "source": [
    "### 아래는 참조용 MGSSL코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "58d4de8b-93b2-4865-b7ac-db977dcab343",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_list = []\n",
    "edge_features_list = []\n",
    "for bond in mol.GetBonds():\n",
    "    i = bond.GetBeginAtomIdx()\n",
    "    j = bond.GetEndAtomIdx()\n",
    "    bt = bond.GetBondType()\n",
    "    edge_feature = [allowable_features['possible_bonds'].index(bt)] + \\\n",
    "                    [int(bond.GetIsConjugated() if bt is not None else 0)] + \\\n",
    "                    [int(bond.IsInRing() if bt is not None else 0)] + \\\n",
    "                    [GROVER_FEATURES['stereo'].index(bond.GetStereo())]\n",
    "    edges_list.append((i, j))\n",
    "    edge_features_list.append(edge_feature)\n",
    "    edges_list.append((j, i))\n",
    "    edge_features_list.append(edge_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a13e48ca-dd42-4394-8d6c-db5267d569e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isatominringofsize(atom_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d625287f-090d-4ca3-9f39-7efc77b8ae3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, False, True, False, False, False]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ring_info.IsAtomInRingOfSize(atom_idx, 3),\n",
    "                ring_info.IsAtomInRingOfSize(atom_idx, 4),\n",
    "                ring_info.IsAtomInRingOfSize(atom_idx, 5),\n",
    "                ring_info.IsAtomInRingOfSize(atom_idx, 6),\n",
    "                ring_info.IsAtomInRingOfSize(atom_idx, 7),\n",
    "                ring_info.IsAtomInRingOfSize(atom_idx, 8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "7ac4a93f-a16f-4289-b234-80a53ebba878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atom.GetAtomicNum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "43af4f74-8ab8-4c86-a0e9-dc8d24cbd0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_atom_type = 100 #including the extra mask tokens\n",
    "num_chirality_tag = 3\n",
    "emb_dim = 300\n",
    "x=torch.tensor(f_atoms)\n",
    "x_embedding1 = torch.nn.Embedding(num_atom_type, emb_dim)\n",
    "x_embedding2 = torch.nn.Embedding(2, emb_dim)\n",
    "x_embedding3 = torch.nn.Embedding(2, emb_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6f4d83-e87b-49c7-a7a9-bd1ec77424be",
   "metadata": {},
   "source": [
    "# Dataset 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5e17f248-2552-4a58-804c-be4089f51171",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from mol_tree import MolTree\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem import AllChem\n",
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import math\n",
    "import os\n",
    "import csv\n",
    "from typing import Union, List\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from rdkit import Chem\n",
    "\n",
    "from grover.topology.mol_tree import MolTree, MolTree_break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "21244f7b-95a1-41cc-bdbc-6d5436b3a139",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle\n",
    "from grover.topology.mol_tree import *\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "508834b1-fe14-4279-a2a6-bf0463627473",
   "metadata": {},
   "outputs": [],
   "source": [
    "#원본"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84f2ee6c-a592-4dd6-9d83-8878a7feb337",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoleculeDataset_grover(Dataset):\n",
    "\n",
    "    def __init__(self, data):\n",
    "        with open(data, 'rb') as f:\n",
    "            self.data = pickle.load(f)\n",
    "        self.n_samples = len(data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        mol_tree = self.data[idx]\n",
    "        return mol_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8bd1ff7-9b28-42ae-8d86-44e2d5ef4fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MoleculeDataset_grover('data/merge/total.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "601b9bb5-1792-4835-afde-bb8492414326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<grover.topology.mol_tree.MolTree_break at 0x7fb87216b350>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc0d36e9-dfed-4a05-9416-f81ad1c6c081",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = train_test_split(dataset, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c2169eb-d183-4556-a470-2f0e8d1a8e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=args.num_workers, collate_fn=lambda x:x, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=2, shuffle=True, num_workers=args.num_workers, collate_fn=lambda x:x, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "790b9e3f-6d09-40fd-bb3c-a69406c665e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:\" + str(args.device)) if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model = GNN(5, args.emb_dim, JK='last', drop_ratio=args.dropout_ratio, gnn_type='gin').to(device)\n",
    "if os.path.exists(args.input_model_file):\n",
    "    model.load_state_dict(torch.load(args.input_model_file))\n",
    "\n",
    "vocab = [x.strip(\"\\r\\n \") for x in open(args.vocab)]\n",
    "vocab = Vocab(vocab)\n",
    "motif_model = Motif_Generation_Grover(vocab, args.hidden_size, device, args.order).to(device)\n",
    "\n",
    "model_list = [model, motif_model]\n",
    "optimizer_model = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.decay)\n",
    "optimizer_motif = optim.Adam(motif_model.parameters(), lr=1e-3, weight_decay=args.decay)\n",
    "\n",
    "optimizer_list = [optimizer_model, optimizer_motif]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "264d86a0-1022-480f-be2f-e9563a22728d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<grover.topology.mol_tree.MolTree_break object at 0x7fb87217cd90>, <grover.topology.mol_tree.MolTree object at 0x7fb8720d3fd0>]\n",
      "[<grover.topology.mol_tree.MolTree object at 0x7fb8720e46d0>, <grover.topology.mol_tree.MolTree_break object at 0x7fb87216b350>]\n",
      "[<grover.topology.mol_tree.MolTree object at 0x7fb8720ea890>, <grover.topology.mol_tree.MolTree object at 0x7fb87214a690>]\n",
      "[<grover.topology.mol_tree.MolTree object at 0x7fb872150790>, <grover.topology.mol_tree.MolTree_break object at 0x7fb8721d3e10>]\n",
      "[<grover.topology.mol_tree.MolTree_break object at 0x7fb87218f310>, <grover.topology.mol_tree.MolTree_break object at 0x7fb87212f3d0>]\n",
      "[<grover.topology.mol_tree.MolTree object at 0x7fb8721464d0>, <grover.topology.mol_tree.MolTree object at 0x7fb8720dd310>]\n",
      "[<grover.topology.mol_tree.MolTree object at 0x7fb872142310>, <grover.topology.mol_tree.MolTree_break object at 0x7fb87215fd10>]\n",
      "[<grover.topology.mol_tree.MolTree_break object at 0x7fb872138f10>, <grover.topology.mol_tree.MolTree_break object at 0x7fb87212a490>]\n"
     ]
    }
   ],
   "source": [
    "for step, batch in enumerate(train_loader):\t# 데이터로더에서 순회 진행바 표시형태로 순회해서 step과 batch대로 반복하자\n",
    "    print(batch)\n",
    "    batch_size = len(batch)\n",
    "\n",
    "    graph_batch = moltree_to_graph_data(batch)\t\t# 분자식을 파이토치 지오메트릭 패키지에서 요구되는 그래프 데이터 형태로 변경해서 배치단위로 저장   /datautils에 있음\n",
    "    #store graph object data in the process stage\t\n",
    "    batch_index = graph_batch.batch.numpy()\t\t\t# 배치내의 배치텐서를 넘파이로 인덱스에 넘겨라\n",
    "    graph_batch = graph_batch.to(device)\t\t\t# 그래프배치는 GPU로 되게"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e5bc759-495a-45fd-a501-45d8b13b7ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataDataBatch(x=[43, 2], edge_index=[2, 92], edge_attr=[92, 2], batch=[43], ptr=[3])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_batch"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b5e4038a-ec60-4c1c-8d9f-e41e926b4d97",
   "metadata": {},
   "source": [
    "class MoleculeDataset_grover(Dataset):\n",
    "\n",
    "    def __init__(self, smiles_path, moltree_path, n_samples):\n",
    "        self.smiles_path = smiles_path\n",
    "        self.moltree_path = moltree_path\n",
    "        self.n_samples = n_samples\n",
    "        self.sample_per_file = len(self.smiles[0]) if len(self.smiles)!=0 else None\n",
    "        self.datapoints = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        mol_tree = self.data[idx]\n",
    "        return mol_tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42d93185-6df9-4d6c-882d-9cb08cbb0e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grover꺼 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68521c23-3e3f-4552-b96d-ef2f08a6646b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_grover(data,\n",
    "               split_type='random',\n",
    "               sizes=(0.8, 0.1, 0.1),\n",
    "               seed=0,\n",
    "               logger=None):\n",
    "    \"\"\"\n",
    "    Split data with given train/validation/test ratio.\n",
    "    :param data:\n",
    "    :param split_type:\n",
    "    :param sizes:\n",
    "    :param seed:\n",
    "    :param logger:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    assert len(sizes) == 3 and sum(sizes) == 1\n",
    "\n",
    "    if split_type == \"random\":\n",
    "        data.shuffle(seed=seed)\n",
    "        data = data.data\n",
    "\n",
    "        train_size = int(sizes[0] * len(data))\n",
    "        train_val_size = int((sizes[0] + sizes[1]) * len(data))\n",
    "\n",
    "        train = data[:train_size]\n",
    "        val = data[train_size:train_val_size]\n",
    "        test = data[train_val_size:]\n",
    "\n",
    "        return BatchMolDataset_motif(train), BatchMolDataset_motif(val), BatchMolDataset_motif(test)\n",
    "    else:\n",
    "        raise NotImplementedError(\"Do not support %s splits\" % split_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e53b59ba-369b-47dc-8c53-7aa22e030a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import torch\n",
    "from torch.utils.data.sampler import Sampler\n",
    "import torch.distributed as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f270a3eb-9487-46f9-8e1c-6e3e055ce44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistributedSampler(Sampler):\n",
    "    \"\"\"Sampler that restricts data loading to a subset of the dataset.\n",
    "\n",
    "    It is especially useful in conjunction with\n",
    "    :class:`torch.nn.parallel.DistributedDataParallel`. In such case, each\n",
    "    process can pass a DistributedSampler instance as a DataLoader sampler,\n",
    "    and load a subset of the original dataset that is exclusive to it.\n",
    "\n",
    "    .. note::\n",
    "        Dataset is assumed to be of constant size.\n",
    "\n",
    "    Arguments:\n",
    "        dataset: Dataset used for sampling.\n",
    "        num_replicas (optional): Number of processes participating in\n",
    "            distributed training.\n",
    "        rank (optional): Rank of the current process within num_replicas.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset, num_replicas=None, rank=None, shuffle=True, sample_per_file=None):\n",
    "        if num_replicas is None:\n",
    "            if not dist.is_available():\n",
    "                raise RuntimeError(\"Requires distributed package to be available\")\n",
    "            num_replicas = dist.get_world_size()\n",
    "        if rank is None:\n",
    "            if not dist.is_available():\n",
    "                raise RuntimeError(\"Requires distributed package to be available\")\n",
    "            rank = dist.get_rank()\n",
    "        self.dataset = dataset\n",
    "        self.num_replicas = num_replicas\n",
    "        self.rank = rank\n",
    "        self.epoch = 0\n",
    "        self.num_samples = int(math.ceil(len(self.dataset) * 1.0 / self.num_replicas))\n",
    "        self.total_size = self.num_samples * self.num_replicas\n",
    "        self.sample_per_file = sample_per_file\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def get_indices(self):\n",
    "\n",
    "        indices = list(range(len(self.dataset)))\n",
    "\n",
    "        if self.sample_per_file is not None:\n",
    "            indices = self.sub_indices_of_rank(indices)\n",
    "        else:\n",
    "            # add extra samples to make it evenly divisible\n",
    "            indices += indices[:(self.total_size - len(indices))]\n",
    "            assert len(indices) == self.total_size\n",
    "            # subsample\n",
    "            s = self.rank * self.num_samples\n",
    "            e = min((self.rank + 1) * self.num_samples, len(indices))\n",
    "\n",
    "            # indices = indices[self.rank:self.total_size:self.num_replicas]\n",
    "            indices = indices[s:e]\n",
    "\n",
    "        if self.shuffle:\n",
    "            g = torch.Generator()\n",
    "            # the seed need to be considered.\n",
    "            g.manual_seed((self.epoch + 1) * (self.rank + 1) * time.time())\n",
    "            idx = torch.randperm(len(indices), generator=g).tolist()\n",
    "            indices = [indices[i] for i in idx]\n",
    "\n",
    "        # disable this since sub_indices_of_rank.\n",
    "        # assert len(indices) == self.num_samples\n",
    "\n",
    "        return indices\n",
    "\n",
    "    def sub_indices_of_rank(self, indices):\n",
    "\n",
    "        # fix generator for each epoch\n",
    "        g = torch.Generator()\n",
    "        # All data should be loaded in each epoch.\n",
    "        g.manual_seed((self.epoch + 1) * 2 + 3)\n",
    "\n",
    "        # the fake file indices to cache\n",
    "        f_indices = list(range(int(math.ceil(len(indices) * 1.0 / self.sample_per_file))))\n",
    "        idx = torch.randperm(len(f_indices), generator=g).tolist()\n",
    "        f_indices = [f_indices[i] for i in idx]\n",
    "\n",
    "        file_per_rank = int(math.ceil(len(f_indices) * 1.0 / self.num_replicas))\n",
    "        # add extra fake file to make it evenly divisible\n",
    "        f_indices += f_indices[:(file_per_rank * self.num_replicas - len(f_indices))]\n",
    "\n",
    "        # divide index by rank\n",
    "        rank_s = self.rank * file_per_rank\n",
    "        rank_e = min((self.rank + 1) * file_per_rank, len(f_indices))\n",
    "\n",
    "        # get file index for this rank\n",
    "        f_indices = f_indices[rank_s:rank_e]\n",
    "        # print(\"f_indices\")\n",
    "        # print(f_indices)\n",
    "        res_indices = []\n",
    "        for fi in f_indices:\n",
    "            # get real indices for this rank\n",
    "            si = fi * self.sample_per_file\n",
    "            ei = min((fi + 1) * self.sample_per_file, len(indices))\n",
    "            cur_idx = [indices[i] for i in range(si, ei)]\n",
    "            res_indices += cur_idx\n",
    "\n",
    "        self.num_samples = len(res_indices)\n",
    "        return res_indices\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.get_indices())\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def set_epoch(self, epoch):\n",
    "        self.epoch = epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "832bb302-dec2-4e99-98c8-8920289219e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoleculeDatapoint_motif:\n",
    "    \"\"\"A MoleculeDatapoint contains a single molecule and its associated features and targets.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 line: List[str],\n",
    "                 args: Namespace = None,\n",
    "                 moltrees: object = None,\n",
    "                 use_compound_names: bool = False):\n",
    "        \"\"\"\n",
    "        Initializes a MoleculeDatapoint, which contains a single molecule.\n",
    "\n",
    "        :param line: A list of strings generated by separating a line in a data CSV file by comma.\n",
    "        :param args: Arguments.\n",
    "        :param features: A numpy array containing additional features (ex. Morgan fingerprint).\n",
    "        :param use_compound_names: Whether the data CSV includes the compound name on each line.\n",
    "        \"\"\"\n",
    "        self.args = None\n",
    "        if args is not None:\n",
    "            self.args = args\n",
    "\n",
    "        self.moltrees = moltrees\n",
    "\n",
    "        if use_compound_names:\n",
    "            self.compound_name = line[0]  # str\n",
    "            line = line[1:]\n",
    "        else:\n",
    "            self.compound_name = None\n",
    "\n",
    "        self.smiles = line[0]  # str\n",
    "\n",
    "        # Create targets\n",
    "        self.targets = [float(x) if x != '' else None for x in line[1:]]\n",
    "        \n",
    "    def set_moltrees(self, moltrees: list):\n",
    "        \"\"\"\n",
    "        Sets the moltree of the molecule.\n",
    "\n",
    "        :param moltree: moltree object\n",
    "        \"\"\"\n",
    "        self.moltrees = moltrees\n",
    "        \n",
    "    def clean_moltree(self):\n",
    "        \"\"\"\n",
    "        clean moltree for memory\n",
    "        \"\"\"\n",
    "        self.moltrees = None\n",
    "\n",
    "    def num_tasks(self) -> int:\n",
    "        \"\"\"\n",
    "        Returns the number of prediction tasks.\n",
    "\n",
    "        :return: The number of tasks.\n",
    "        \"\"\"\n",
    "        return len(self.targets)\n",
    "\n",
    "    def set_targets(self, targets: List[float]):\n",
    "        \"\"\"\n",
    "        Sets the targets of a molecule.\n",
    "\n",
    "        :param targets: A list of floats containing the targets.\n",
    "        \"\"\"\n",
    "        self.targets = targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad9475f1-42a4-4365-9241-b95ce8b4ec5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchDatapoint_motif:\n",
    "    def __init__(self,\n",
    "                 smiles_file,\n",
    "                 moltree_file,\n",
    "                 n_samples,\n",
    "                 ):\n",
    "        self.smiles_file = smiles_file\n",
    "        self.moltree_file = moltree_file\n",
    "        # deal with the last batch graph numbers.\n",
    "        self.n_samples = n_samples\n",
    "        self.datapoints = None\n",
    "\n",
    "    def load_datapoints(self):\n",
    "        moltrees = self.load_moltree()\n",
    "        self.datapoints = []\n",
    "\n",
    "        with open(self.smiles_file) as f:\n",
    "            reader = csv.reader(f)\n",
    "            next(reader)\n",
    "            for i, line in enumerate(reader):\n",
    "                # line = line[0]\n",
    "                d = MoleculeDatapoint_motif(line=line,\n",
    "                                      moltrees=moltrees[i])\n",
    "                self.datapoints.append(d)\n",
    "        f.close()\n",
    "\n",
    "        assert len(self.datapoints) == self.n_samples\n",
    "    \n",
    "    def load_moltree(self):\n",
    "        with open(self.moltree_file, 'rb') as f:\n",
    "            moltrees = pickle.load(f)            \n",
    "        return moltrees\n",
    "\n",
    "    def shuffle(self):\n",
    "        pass\n",
    "\n",
    "    def clean_cache(self):\n",
    "        del self.datapoints\n",
    "        self.datapoints = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        assert self.datapoints is not None\n",
    "        return self.datapoints[idx]\n",
    "\n",
    "    def is_loaded(self):\n",
    "        return self.datapoints is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebeb678a-7801-458f-8c90-b845e26732b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchMolDataset_motif(Dataset):\n",
    "    def __init__(self, data: List[BatchDatapoint_motif],\n",
    "                 graph_per_file=None):\n",
    "        self.data = data\n",
    "\n",
    "        self.len = 0\n",
    "        for d in self.data:\n",
    "            self.len += len(d)\n",
    "        if graph_per_file is not None:\n",
    "            self.sample_per_file = graph_per_file\n",
    "        else:\n",
    "            self.sample_per_file = len(self.data[0]) if len(self.data) != 0 else None\n",
    "\n",
    "    def shuffle(self, seed: int = None):\n",
    "        pass\n",
    "\n",
    "    def clean_cache(self):\n",
    "        for d in self.data:\n",
    "            d.clean_cache()\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx) -> Union[MoleculeDatapoint_motif, List[MoleculeDatapoint_motif]]:\n",
    "        # print(idx)\n",
    "        dp_idx = int(idx / self.sample_per_file)\n",
    "        real_idx = idx % self.sample_per_file\n",
    "        return self.data[dp_idx][real_idx]\n",
    "\n",
    "    def load_data(self, idx):\n",
    "        dp_idx = int(idx / self.sample_per_file)\n",
    "        if not self.data[dp_idx].is_loaded():\n",
    "            self.data[dp_idx].load_datapoints()\n",
    "\n",
    "    def count_loaded_datapoints(self):\n",
    "        res = 0\n",
    "        for d in self.data:\n",
    "            if d.is_loaded():\n",
    "                res += 1\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f1009e8-097d-43aa-9f4e-bdb14665aba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_motif_data(data_path, logger=None):\n",
    "    \"\"\"\n",
    "    Load data from the data_path.\n",
    "    :param data_path: the data_path.\n",
    "    :param logger: the logger.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    debug = logger.debug if logger is not None else print\n",
    "    summary_path = os.path.join(data_path, \"summary.txt\")\n",
    "    smiles_path = os.path.join(data_path, \"graph\")\n",
    "    moltree_path = os.path.join(data_path, \"moltrees\")\n",
    "\n",
    "    fin = open(summary_path)\n",
    "    n_files = int(fin.readline().strip().split(\":\")[-1])\n",
    "    n_samples = int(fin.readline().strip().split(\":\")[-1])\n",
    "    sample_per_file = int(fin.readline().strip().split(\":\")[-1])\n",
    "    debug(\"Loading data:\")\n",
    "    debug(\"Number of files: %d\" % n_files)\n",
    "    debug(\"Number of samples: %d\" % n_samples)\n",
    "    debug(\"Samples/file: %d\" % sample_per_file)\n",
    "\n",
    "    datapoints = []\n",
    "    for i in range(n_files):\n",
    "        smiles_path_i = os.path.join(smiles_path, str(i) + \".csv\")\n",
    "        moltree_path_i = os.path.join(moltree_path, str(i) + \".p\")\n",
    "        n_samples_i = sample_per_file if i != (n_files - 1) else n_samples % sample_per_file\n",
    "        datapoints.append(BatchDatapoint_motif(smiles_path_i, moltree_path_i, n_samples_i))\n",
    "    return BatchMolDataset_motif(datapoints), sample_per_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc5244ac-67c9-4912-8acf-47f362425bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroverMotifCollator(object):\n",
    "    def __init__(self, shared_dict, args):\n",
    "        self.args = args\n",
    "        self.shared_dict = shared_dict\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        smiles_batch = [d.smiles for d in batch] # 여기서 말하는 batch는 batchmoldataset_motif다 그리고 d는 batchdatapoint_motif고\n",
    "        #batchgraph = mol2graph(smiles_batch, self.shared_dict, self.args).get_components()\n",
    "\n",
    "        #fgroup_label = torch.Tensor(np.array([d.features for d in batch])).float()\n",
    "        moltree_batch = [d.moltrees for d in batch]\n",
    "        \n",
    "        # may be some mask here\n",
    "\n",
    "        return moltree_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7c277b3-dfa6-454f-a410-0b6a17443365",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_load_data(dataset: BatchMolDataset_motif, rank: int, num_replicas: int, sample_per_file: int = None, epoch: int = 0):\n",
    "    \"\"\"\n",
    "    Pre-load data at the beginning of each epoch.\n",
    "    :param dataset: the training dataset.\n",
    "    :param rank: the rank of the current worker.\n",
    "    :param num_replicas: the replicas.\n",
    "    :param sample_per_file: the number of the data points in each file. When sample_per_file is None, all data will be\n",
    "    loaded. It implies the testing phase. (TODO: bad design here.)\n",
    "    :param epoch: the epoch number.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    mock_sampler = DistributedSampler(dataset, num_replicas=num_replicas, rank=rank, shuffle=False,\n",
    "                                      sample_per_file=sample_per_file)\n",
    "    mock_sampler.set_epoch(epoch)\n",
    "    pre_indices = mock_sampler.get_indices()\n",
    "    for i in pre_indices:\n",
    "        dataset.load_data(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94b99966-6cb5-4792-a19a-5a575bc0631c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data:\n",
      "Number of files: 20\n",
      "Number of samples: 20000\n",
      "Samples/file: 1000\n"
     ]
    }
   ],
   "source": [
    "grover_data, sample_per_file = get_motif_data(args.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e64d392-fe0c-4b9d-b04d-5ec1f23b8c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, _ = split_data_grover(grover_data, sizes=(0.5,0.5,0), seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2321c993-4885-49ef-a9e9-335127c01ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_dict = {}\n",
    "GMC = GroverMotifCollator(shared_dict=shared_dict, args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55085e47-9ace-4c76-bac4-5a78956a6507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.BatchMolDataset_motif at 0x7f097019af90>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c10739d-2d37-4af8-9d28-6363baa69254",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5145755-1c2a-443d-9558-834e37e0d45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_load_data(train, rank=0, num_replicas=1)\n",
    "train_grover_loader = DataLoader(train, batch_size=2, shuffle=True, num_workers=args.num_workers, collate_fn=GMC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0726306-95bc-4288-a850-655bcc6696f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<grover.topology.mol_tree.MolTree object at 0x7f089996bf50>, <grover.topology.mol_tree.MolTree object at 0x7f0899a951d0>]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-58ad417fd48d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#store graph object data in the process stage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                     \u001b[0;31m# 배치내의 배치텐서를 넘파이로 인덱스에 넘겨라\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mgraph_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m                        \u001b[0;31m# 그래프배치는 GPU로 되게\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "for _, batch in enumerate(train_grover_loader):\n",
    "    print(batch)\n",
    "    batch_size = len(batch)\n",
    "\n",
    "    graph_batch = moltree_to_graph_data(batch)\t\t# 분자식을 파이토치 지오메트릭 패키지에서 요구되는 그래프 데이터 형태로 변경해서 배치단위로 저장   /datautils에 있음\n",
    "    #store graph object data in the process stage\t\n",
    "    batch_index = graph_batch.batch.numpy()\t\t\t# 배치내의 배치텐서를 넘파이로 인덱스에 넘겨라\n",
    "    graph_batch = graph_batch.to(device)\t\t\t# 그래프배치는 GPU로 되게"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0d13c24b-531f-4872-819e-5abed88c5d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataDataBatch(x=[43, 2], edge_index=[2, 92], edge_attr=[92, 2], batch=[43], ptr=[3])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146edf8d-78a7-4fb7-80e2-b4cbfcf87340",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddb4bcac-6fac-4833-a441-502a7f9f5f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree, softmax\n",
    "from torch_geometric.nn import global_add_pool, global_mean_pool, global_max_pool, GlobalAttention, Set2Set\n",
    "import torch.nn.functional as F\n",
    "from torch_scatter import scatter_add\n",
    "from torch_geometric.nn.inits import glorot, zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fab69368-5dad-4e44-8c5a-0536223d2060",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GINConv_grover(MessagePassing):\n",
    "    \"\"\"\n",
    "    Extension of GIN aggregation to incorporate edge information by concatenation.\n",
    "\n",
    "    Args:\n",
    "        emb_dim (int): dimensionality of embeddings for nodes and edges.\n",
    "        embed_input (bool): whether to embed input or not. \n",
    "        \n",
    "\n",
    "    See https://arxiv.org/abs/1810.00826\n",
    "    \"\"\"\n",
    "    def __init__(self, emb_dim, aggr = \"add\"):\n",
    "        super(GINConv, self).__init__()\n",
    "        #multi-layer perceptron\n",
    "        self.mlp = torch.nn.Sequential(torch.nn.Linear(emb_dim, 2*emb_dim), torch.nn.ReLU(), torch.nn.Linear(2*emb_dim, emb_dim))\n",
    "        self.edge_embedding = torch.nn.Linear(bond_fdim, emb_dim)\n",
    "\n",
    "        self.aggr = aggr\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        #add self loops in the edge space\n",
    "        edge_index = add_self_loops(edge_index, num_nodes = x.size(0))\n",
    "\n",
    "        #add features corresponding to self-loop edges.\n",
    "        self_loop_attr = torch.zeros(x.size(0), 2)\n",
    "        self_loop_attr[:,0] = 4 #bond type for self-loop edge\n",
    "        self_loop_attr = self_loop_attr.to(edge_attr.device).to(edge_attr.dtype)\n",
    "        edge_attr = torch.cat((edge_attr, self_loop_attr), dim = 0)\n",
    "\n",
    "        edge_embeddings = self.edge_embedding(edge_attr)\n",
    "\n",
    "        return self.propagate(edge_index[0], x=x, edge_attr=edge_embeddings)\n",
    "\n",
    "    def message(self, x_j, edge_attr):\n",
    "        return x_j + edge_attr\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        return self.mlp(aggr_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b54000e0-70c7-4d2d-8ee6-ffcff338f6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN_grover(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    Args:\n",
    "        num_layer (int): the number of GNN layers\n",
    "        emb_dim (int): dimensionality of embeddings\n",
    "        JK (str): last, concat, max or sum.\n",
    "        max_pool_layer (int): the layer from which we use max pool rather than add pool for neighbor aggregation\n",
    "        drop_ratio (float): dropout rate\n",
    "        gnn_type: gin, gcn, graphsage, gat\n",
    "\n",
    "    Output:\n",
    "        node representations\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, num_layer, emb_dim, JK = \"last\", drop_ratio = 0, gnn_type = \"gin\"):\n",
    "        super(GNN, self).__init__()\n",
    "        self.num_layer = num_layer\n",
    "        self.drop_ratio = drop_ratio\n",
    "        self.JK = JK\n",
    "\n",
    "        if self.num_layer < 2:\n",
    "            raise ValueError(\"Number of GNN layers must be greater than 1.\")\n",
    "\n",
    "        self.x_embedding = torch.nn.Linear(atom_fdim, emb_dim, bias=True)\n",
    "\n",
    "        ###List of MLPs\n",
    "        self.gnns = torch.nn.ModuleList()\n",
    "        for layer in range(num_layer):\n",
    "            if gnn_type == \"gin\":\n",
    "                self.gnns.append(GINConv(emb_dim, aggr = \"add\"))\n",
    "            elif gnn_type == \"gcn\":\n",
    "                self.gnns.append(GCNConv(emb_dim))\n",
    "            elif gnn_type == \"gat\":\n",
    "                self.gnns.append(GATConv(emb_dim))\n",
    "            elif gnn_type == \"graphsage\":\n",
    "                self.gnns.append(GraphSAGEConv(emb_dim))\n",
    "\n",
    "        ###List of batchnorms\n",
    "        self.batch_norms = torch.nn.ModuleList()\n",
    "        for layer in range(num_layer):\n",
    "            self.batch_norms.append(torch.nn.BatchNorm1d(emb_dim))\n",
    "\n",
    "    #def forward(self, x, edge_index, edge_attr):\n",
    "    def forward(self, *argv):\n",
    "        if len(argv) == 3:\n",
    "            x, edge_index, edge_attr = argv[0], argv[1], argv[2]\n",
    "        elif len(argv) == 1:\n",
    "            data = argv[0]\n",
    "            x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        else:\n",
    "            raise ValueError(\"unmatched number of arguments.\")\n",
    "\n",
    "        x = self.x_embedding(x)\n",
    "\n",
    "        h_list = [x]\n",
    "        for layer in range(self.num_layer):\n",
    "            h = self.gnns[layer](h_list[layer], edge_index, edge_attr)\n",
    "            h = self.batch_norms[layer](h)\n",
    "            #h = F.dropout(F.relu(h), self.drop_ratio, training = self.training)\n",
    "            if layer == self.num_layer - 1:\n",
    "                #remove relu for the last layer\n",
    "                h = F.dropout(h, self.drop_ratio, training = self.training)\n",
    "            else:\n",
    "                h = F.dropout(F.relu(h), self.drop_ratio, training = self.training)\n",
    "            h_list.append(h)\n",
    "\n",
    "        ### Different implementations of Jk-concat   #레이어간 노드 기능들을 어떻게 할건지, 기본은 Last다\n",
    "        if self.JK == \"concat\":\n",
    "            node_representation = torch.cat(h_list, dim = 1)\n",
    "        elif self.JK == \"last\":\n",
    "            node_representation = h_list[-1]\n",
    "        elif self.JK == \"max\":\n",
    "            h_list = [h.unsqueeze_(0) for h in h_list]\n",
    "            node_representation = torch.max(torch.cat(h_list, dim = 0), dim = 0)[0]\n",
    "        elif self.JK == \"sum\":\n",
    "            h_list = [h.unsqueeze_(0) for h in h_list]\n",
    "            node_representation = torch.sum(torch.cat(h_list, dim = 0), dim = 0)[0]\n",
    "\n",
    "        return node_representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e33aa4a-eeb1-4db8-a7f1-72afe0159449",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:\" + str(args.device)) if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model = GNN(5, 1200, JK='last', drop_ratio=0.2, gnn_type='gin').to(device)\n",
    "\n",
    "vocab = [x.strip(\"\\r\\n \") for x in open('../../grover/data/merge/clique.txt')]\n",
    "vocab = Vocab(vocab)\n",
    "motif_model = Motif_Generation(vocab, 1200, 56, 3, device, 'dfs').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f51d85-9543-496b-8cc3-42b7f36962d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4108af2c-d6f6-4414-989a-eb89c693f0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for step, batch in enumerate(tqdm(loader, desc=\"Iteration\")):\t# 데이터로더에서 순회 진행바 표시형태로 순회해서 step과 batch대로 반복하자\n",
    "\n",
    "    batch_size = len(batch)\n",
    "\n",
    "    graph_batch = moltree_to_graph_data(batch)\t\t# 분자식을 파이토치 지오메트릭 패키지에서 요구되는 그래프 데이터 형태로 변경해서 배치단위로 저장   /datautils에 있음\n",
    "    #store graph object data in the process stage\t\n",
    "    batch_index = graph_batch.batch.numpy()\t\t\t# 배치내의 배치텐서를 넘파이로 인덱스에 넘겨라\n",
    "    graph_batch = graph_batch.cuda()\t\t\t# 그래프배치는 GPU로 되게\n",
    "    node_rep = model(graph_batch.x, graph_batch.edge_index, graph_batch.edge_attr)\t# GNN모델에 그래프(x, 엣지인덱스, 엣지의 특성) 투입\n",
    "    node_rep = group_node_rep(node_rep, batch_index, batch_size)\t\t\t# rep는 representation의 줄임말로 노드 표현을 의미\n",
    "    loss, wacc, tacc = motif_model(batch, node_rep)\t\t# motif모델에서 손실, motif정확도, 위상 정확도 출력\n",
    "    if step == 1 : break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fb5feb9c-19ca-4561-b810-9f31a903ad36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.2578,  0.1756, -0.4891,  ...,  0.2525,  0.0000, -1.0834],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.7313, -0.0132, -0.3913],\n",
       "         [-0.0000,  0.8658, -0.4621,  ..., -0.1646,  0.2450, -0.5645],\n",
       "         ...,\n",
       "         [-0.5576, -0.3981,  0.0000,  ..., -0.4005,  0.0000,  0.2969],\n",
       "         [-0.0000, -0.0094,  0.7077,  ..., -0.0000,  1.3705,  0.0000],\n",
       "         [-0.1629, -0.0094,  0.7077,  ..., -0.4874,  1.3705,  0.1655]],\n",
       "        device='cuda:0', grad_fn=<SliceBackward0>),\n",
       " tensor([[-6.1990e-01,  1.8907e-01, -0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00, -0.0000e+00],\n",
       "         [-0.0000e+00,  0.0000e+00, -3.6910e-01,  ...,  1.4765e+00,\n",
       "           0.0000e+00,  4.6965e-01],\n",
       "         [-6.5697e-01,  1.9685e-01, -0.0000e+00,  ...,  0.0000e+00,\n",
       "           1.1914e+00,  3.4645e-01],\n",
       "         ...,\n",
       "         [ 8.1637e-01,  4.8261e-01, -2.5783e+00,  ...,  4.8366e-01,\n",
       "           7.1742e-01,  7.3027e-01],\n",
       "         [ 0.0000e+00,  4.0174e-01, -0.0000e+00,  ..., -2.3614e-01,\n",
       "           9.5082e-01,  2.8971e-01],\n",
       "         [ 2.4533e-01,  1.0584e-03,  1.0557e+00,  ..., -4.9968e-01,\n",
       "          -5.9718e-01, -0.0000e+00]], device='cuda:0', grad_fn=<SliceBackward0>),\n",
       " tensor([[-0.6908, -0.6718, -0.2811,  ..., -0.3495,  1.8354, -1.0242],\n",
       "         [-0.0000, -0.8916,  0.2737,  ..., -0.1534,  1.5198, -0.9354],\n",
       "         [-0.1798, -0.2494,  0.5737,  ..., -0.4713,  0.7016, -1.5036],\n",
       "         ...,\n",
       "         [-0.4861,  0.8628, -0.2589,  ...,  0.4436, -1.8641,  0.0000],\n",
       "         [-0.4989,  0.5246, -0.3383,  ...,  1.2022, -0.0000,  0.0000],\n",
       "         [-0.0000,  0.3542,  1.1479,  ..., -0.0000, -0.3192,  0.0000]],\n",
       "        device='cuda:0', grad_fn=<SliceBackward0>),\n",
       " tensor([[ 0.5932, -0.0000, -0.0000,  ..., -0.3446,  0.0000, -1.5769],\n",
       "         [ 0.3345, -0.0000, -0.6065,  ...,  0.0044,  1.0270, -0.9386],\n",
       "         [-0.0000, -0.9763, -0.3778,  ..., -0.0000,  0.6835, -0.5645],\n",
       "         ...,\n",
       "         [ 0.7036, -0.2992, -0.0523,  ..., -0.1771, -0.6033, -0.1564],\n",
       "         [ 0.5403, -0.2964, -0.1112,  ..., -1.0924,  0.0000, -0.9041],\n",
       "         [-0.2289, -0.3331, -0.1618,  ..., -1.2311,  0.5197, -1.1184]],\n",
       "        device='cuda:0', grad_fn=<SliceBackward0>),\n",
       " tensor([[ 0.3521,  0.1859,  0.0000,  ..., -0.7173,  0.8080, -0.0000],\n",
       "         [ 1.0957,  0.7374,  0.3868,  ..., -1.1504,  0.0000, -0.5582],\n",
       "         [ 1.9820,  1.4932,  0.0000,  ..., -1.0559,  0.0000, -0.4104],\n",
       "         ...,\n",
       "         [ 0.0000,  0.9950,  0.0095,  ...,  0.1716, -0.1555,  0.1747],\n",
       "         [ 0.4143,  0.1127, -0.4833,  ...,  0.5268, -0.0517,  0.0696],\n",
       "         [ 1.3341,  1.1630, -0.5316,  ..., -0.2829,  0.0000, -0.7527]],\n",
       "        device='cuda:0', grad_fn=<SliceBackward0>),\n",
       " tensor([[-0.3187, -0.6897, -1.3011,  ...,  0.8609,  1.6625, -1.8954],\n",
       "         [-0.5430, -0.9418, -0.8175,  ...,  2.6446,  0.8657, -0.0000],\n",
       "         [-0.0000, -0.3888, -1.6131,  ...,  3.0073,  1.6064, -1.5962],\n",
       "         ...,\n",
       "         [-1.3568,  1.2112,  0.3603,  ..., -1.4934, -0.5864,  0.0000],\n",
       "         [-0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.9445,  1.1358],\n",
       "         [-0.9114,  1.4815,  0.3085,  ..., -0.2898, -0.0000,  0.2899]],\n",
       "        device='cuda:0', grad_fn=<SliceBackward0>),\n",
       " tensor([[ 0.2002,  0.6375, -0.2561,  ..., -0.9047, -0.1198, -0.0000],\n",
       "         [-0.0000,  2.0408, -0.0000,  ..., -1.3941, -1.1910, -0.8675],\n",
       "         [ 0.1728,  1.8652, -0.5595,  ..., -1.0890, -0.4009, -0.1738],\n",
       "         ...,\n",
       "         [-1.0934,  1.5983, -0.0000,  ..., -1.5005,  0.4736, -0.2263],\n",
       "         [-0.6801,  0.7323, -1.1680,  ..., -1.4712,  1.4676, -0.7256],\n",
       "         [-0.6278,  1.4329, -0.5871,  ..., -1.1181, -0.5366, -0.7143]],\n",
       "        device='cuda:0', grad_fn=<SliceBackward0>),\n",
       " tensor([[ 0.1986, -0.5978, -0.2422,  ..., -0.4995,  0.7331, -0.9407],\n",
       "         [ 1.2212, -0.6799,  0.0000,  ...,  0.1195,  0.1237,  0.3868],\n",
       "         [ 1.7953, -1.3504,  0.0000,  ...,  2.1954, -0.2053,  2.2556],\n",
       "         ...,\n",
       "         [ 1.6925, -0.0000,  0.0000,  ...,  0.0000, -3.6603,  2.5537],\n",
       "         [ 0.1945, -0.0000,  0.5186,  ...,  0.9206, -0.6658, -0.0000],\n",
       "         [ 0.0495, -0.8343,  1.0500,  ...,  0.9668, -0.8292, -0.7344]],\n",
       "        device='cuda:0', grad_fn=<SliceBackward0>),\n",
       " tensor([[-0.9310, -0.2578,  1.0239,  ..., -0.4743,  0.3658, -0.3999],\n",
       "         [-0.0000, -0.1344,  1.7245,  ...,  2.1166, -2.3770,  1.4540],\n",
       "         [ 0.0359, -0.0000,  1.6019,  ...,  0.3423, -0.2969,  0.2522],\n",
       "         ...,\n",
       "         [-4.8945,  0.0000, -0.2494,  ...,  2.8463, -0.0000,  0.9219],\n",
       "         [-2.0661,  0.6940, -0.7401,  ..., -0.0000, -1.6447, -1.5061],\n",
       "         [-0.0000,  0.3870,  2.0821,  ...,  3.0859, -4.8579,  3.1114]],\n",
       "        device='cuda:0', grad_fn=<SliceBackward0>),\n",
       " tensor([[ 0.6606, -0.9888,  0.0807,  ..., -1.2047,  0.0000, -0.8204],\n",
       "         [ 1.1093, -0.9184, -0.0604,  ..., -1.2245,  0.4298, -0.4332],\n",
       "         [ 0.8848, -0.7659, -0.0358,  ..., -1.0839, -0.0207, -0.2716],\n",
       "         ...,\n",
       "         [-0.6927, -0.5471,  0.0000,  ..., -1.7711, -1.0334, -1.8135],\n",
       "         [ 0.0000, -0.0000,  3.0401,  ...,  2.8055,  2.5932,  4.0598],\n",
       "         [-0.8139, -1.0305,  1.5441,  ...,  0.0000,  1.4405,  2.3234]],\n",
       "        device='cuda:0', grad_fn=<SliceBackward0>),\n",
       " tensor([[-0.2969, -0.3461, -0.0503,  ...,  0.6661, -0.0469, -0.7180],\n",
       "         [ 1.6749, -1.3083,  0.0000,  ...,  0.7705, -2.4690,  0.0445],\n",
       "         [-0.0637, -0.4863, -0.4129,  ...,  0.5688, -0.7846, -0.3903],\n",
       "         ...,\n",
       "         [ 0.1786, -1.1293, -1.8555,  ...,  0.4244,  0.3452, -0.0000],\n",
       "         [ 0.5216, -1.0108, -0.0000,  ...,  0.0000,  0.0000, -0.0675],\n",
       "         [ 0.0000, -2.0005,  0.6507,  ...,  0.0000, -0.0000,  0.1049]],\n",
       "        device='cuda:0', grad_fn=<SliceBackward0>),\n",
       " tensor([[-1.1309, -0.3715, -0.0000,  ..., -1.6429, -0.7790,  0.1800],\n",
       "         [-2.5627,  0.7604, -0.8360,  ..., -2.4800, -3.2872,  1.8185],\n",
       "         [-0.0000, -0.8325, -0.5930,  ..., -1.0487, -0.8721,  0.0000],\n",
       "         ...,\n",
       "         [-1.4889, -0.2981,  0.7238,  ...,  1.5436, -0.3219,  0.5592],\n",
       "         [-1.6538, -1.3910,  1.6158,  ...,  0.0000, -1.0883,  0.0000],\n",
       "         [-2.1160, -0.0000,  2.1366,  ...,  0.4360, -3.0158,  1.1605]],\n",
       "        device='cuda:0', grad_fn=<SliceBackward0>),\n",
       " tensor([[-0.0000,  0.2812, -0.9048,  ..., -0.0000,  0.5567, -0.8281],\n",
       "         [-1.3047,  1.3970, -0.9138,  ...,  0.0000, -0.0000, -0.1809],\n",
       "         [-0.0000,  1.4300,  0.3703,  ..., -0.1102, -0.8940, -0.0000],\n",
       "         ...,\n",
       "         [-1.0202,  1.0401, -0.2307,  ..., -0.1177, -0.4032, -0.0078],\n",
       "         [-1.4439,  0.0000, -0.9467,  ..., -0.0000, -0.0000,  0.0841],\n",
       "         [-1.0500,  0.0000, -0.7509,  ..., -0.7554,  0.0000, -0.9033]],\n",
       "        device='cuda:0', grad_fn=<SliceBackward0>),\n",
       " tensor([[-0.8078, -0.2969,  0.0391,  ..., -0.2257,  0.6127, -0.9306],\n",
       "         [-0.7236, -0.0000,  0.0270,  ..., -0.6836,  0.0821, -0.5212],\n",
       "         [-0.3494, -1.7221, -0.0000,  ..., -2.3027, -1.3472, -0.3256],\n",
       "         ...,\n",
       "         [-0.1011,  0.0000,  2.6622,  ...,  0.5664, -0.0000, -0.0032],\n",
       "         [ 0.8807, -0.9693, -0.3838,  ..., -0.2496, -0.6826,  0.0000],\n",
       "         [-0.6826, -1.8648, -1.2487,  ..., -3.1571, -0.9265, -0.5265]],\n",
       "        device='cuda:0', grad_fn=<SliceBackward0>),\n",
       " tensor([[ 0.0000,  0.6719,  0.7760,  ..., -0.0000,  0.4745, -0.6754],\n",
       "         [ 0.4016,  1.7573,  1.6420,  ...,  0.1808, -0.0619,  0.0000],\n",
       "         [ 0.0315,  0.8625,  0.0000,  ..., -0.7038,  0.6234, -0.6789],\n",
       "         ...,\n",
       "         [-0.3129,  0.5451, -0.0000,  ..., -1.9809,  0.0416,  0.4152],\n",
       "         [-0.1619,  0.0956, -0.4744,  ..., -1.1223,  0.2084,  0.2598],\n",
       "         [-0.1416, -0.3981, -0.2492,  ..., -0.6033,  0.0000,  0.1868]],\n",
       "        device='cuda:0', grad_fn=<SliceBackward0>),\n",
       " tensor([[-0.1432,  0.0142, -0.9287,  ..., -1.2578,  0.6351, -0.1551],\n",
       "         [-0.2369, -0.0729, -1.8005,  ..., -0.6522,  0.3261,  1.1629],\n",
       "         [ 1.1158, -0.1151, -2.0481,  ..., -1.8638,  0.0099,  1.9472],\n",
       "         ...,\n",
       "         [ 0.0000,  0.8443,  0.6016,  ...,  0.0000,  0.0000,  0.8793],\n",
       "         [ 0.0000,  0.1763,  0.4938,  ...,  0.0000,  0.0000, -0.2690],\n",
       "         [ 1.0234, -0.1089, -1.7670,  ..., -1.6339,  0.0000,  1.4033]],\n",
       "        device='cuda:0', grad_fn=<SliceBackward0>),\n",
       " tensor([[-0.9792,  0.0000, -0.0000,  ..., -0.0000,  0.3662, -0.0000],\n",
       "         [-1.2099,  0.3088, -0.0687,  ...,  0.1049, -0.1050,  0.8963],\n",
       "         [-0.7152,  1.5888,  0.2829,  ...,  0.2823, -0.7180,  1.2368],\n",
       "         ...,\n",
       "         [-0.7563, -0.8546, -1.1460,  ..., -0.0914,  0.4733, -0.0000],\n",
       "         [-1.1458, -0.6623, -2.2281,  ..., -0.0420,  0.4417,  0.0199],\n",
       "         [-0.0403, -0.2202, -0.0000,  ...,  0.0000,  1.4229, -0.0696]],\n",
       "        device='cuda:0', grad_fn=<SliceBackward0>),\n",
       " tensor([[-0.8608,  0.2881, -0.7328,  ..., -0.7071,  0.9933, -0.9396],\n",
       "         [-1.1394,  0.9343, -0.8381,  ..., -0.0000,  0.6615, -0.3435],\n",
       "         [-0.0000,  0.9865, -0.5401,  ..., -1.8499, -0.1390, -0.2688],\n",
       "         ...,\n",
       "         [-0.3144,  0.6096, -0.0000,  ..., -0.4552,  0.9596, -1.2616],\n",
       "         [-0.7072,  0.9889,  0.0000,  ...,  0.2068,  0.6766, -1.1468],\n",
       "         [-0.2206,  0.0000,  0.0000,  ...,  0.4699,  0.0000, -0.0568]],\n",
       "        device='cuda:0', grad_fn=<SliceBackward0>),\n",
       " tensor([[-0.3042, -1.2380, -1.6868,  ...,  0.9442,  0.0723, -0.6680],\n",
       "         [ 0.4175, -2.7452, -0.0000,  ...,  1.8767, -0.5758,  0.3716],\n",
       "         [ 0.1367, -2.9756, -1.5697,  ...,  2.8583, -1.3408,  0.5852],\n",
       "         ...,\n",
       "         [ 0.0000, -2.1586, -1.1266,  ...,  0.4894, -0.0000,  0.7100],\n",
       "         [-0.0441, -1.5994, -1.1766,  ...,  0.0000, -0.0000, -0.5276],\n",
       "         [ 0.0109, -2.0323, -1.8037,  ...,  2.5233, -0.9424, -0.6646]],\n",
       "        device='cuda:0', grad_fn=<SliceBackward0>),\n",
       " tensor([[-0.4732,  0.2988, -0.8299,  ..., -0.7061,  0.8475, -0.1174],\n",
       "         [-0.0000,  0.0000, -1.5739,  ..., -0.4955,  0.2645,  0.0000],\n",
       "         [ 0.1409,  1.1120, -1.3753,  ...,  0.5306, -0.2380,  2.3447],\n",
       "         ...,\n",
       "         [-1.5004,  0.0000,  0.0000,  ..., -0.1954, -0.0000, -0.4716],\n",
       "         [-0.9699, -0.1717, -0.2866,  ..., -0.4516,  0.0000, -1.4127],\n",
       "         [-0.0000,  0.9354, -1.2337,  ...,  0.1573,  0.2438,  2.1667]],\n",
       "        device='cuda:0', grad_fn=<SliceBackward0>),\n",
       " tensor([[-0.3758, -0.4024, -0.7035,  ..., -0.3978,  0.5046, -0.4361],\n",
       "         [-0.0095, -0.0600, -0.9787,  ..., -0.1183,  0.5411,  1.1105],\n",
       "         [-0.0104, -0.4102, -0.7791,  ...,  0.0185,  0.6959,  0.2065],\n",
       "         ...,\n",
       "         [ 0.6402, -0.0000,  0.3494,  ..., -0.7096,  0.7673,  0.5839],\n",
       "         [ 0.1171, -0.2798, -0.4097,  ..., -0.7708,  1.2168, -0.2182],\n",
       "         [ 0.2212,  0.3375,  0.0559,  ..., -0.6318,  0.0000,  0.0000]],\n",
       "        device='cuda:0', grad_fn=<SliceBackward0>),\n",
       " tensor([[ 0.0000, -0.1941, -0.6052,  ..., -1.5882,  0.0000, -0.0534],\n",
       "         [ 1.6278,  0.9202, -0.0000,  ..., -2.5660,  1.5951,  1.1151],\n",
       "         [ 1.5126,  0.4161, -0.5703,  ..., -2.0034,  1.0616,  0.5919],\n",
       "         ...,\n",
       "         [-0.1631, -0.5175,  0.9562,  ..., -0.0492, -1.2052, -0.4645],\n",
       "         [-0.1523,  0.0000,  1.0716,  ...,  1.2950,  1.3540, -1.2826],\n",
       "         [ 1.0069,  1.1267, -0.1298,  ..., -1.8239,  1.0700,  0.0872]],\n",
       "        device='cuda:0', grad_fn=<SliceBackward0>),\n",
       " tensor([[ 0.0000,  0.0038, -1.1240,  ...,  0.1233,  0.7734, -0.4959],\n",
       "         [ 2.5825,  0.2738, -0.8552,  ...,  1.5754, -0.5582,  0.4676],\n",
       "         [ 0.7527,  0.2540, -1.8033,  ...,  0.6849, -0.7059,  0.0000],\n",
       "         ...,\n",
       "         [ 1.6931,  1.0186, -0.4950,  ..., -0.2454,  1.3352, -0.6064],\n",
       "         [ 0.5553,  0.4476, -0.0000,  ..., -1.2905,  0.0000, -0.4191],\n",
       "         [ 0.0000,  0.4258, -0.4038,  ..., -0.0000, -0.1999, -0.7653]],\n",
       "        device='cuda:0', grad_fn=<SliceBackward0>),\n",
       " tensor([[-0.1997, -0.0401, -0.2776,  ...,  0.3231,  0.5055, -0.0000],\n",
       "         [ 0.1980, -0.0227, -0.1834,  ...,  0.0000, -0.1938,  1.1294],\n",
       "         [ 0.4702,  0.2752, -0.1533,  ...,  1.4202, -0.4625,  1.4430],\n",
       "         ...,\n",
       "         [-0.6826,  1.1617,  0.0000,  ...,  0.0000, -1.1089, -2.4353],\n",
       "         [-0.0000,  1.9081,  1.3497,  ...,  0.7021, -0.0000, -2.8263],\n",
       "         [-1.6462,  1.4728,  0.6980,  ...,  0.5011, -0.0000, -2.6068]],\n",
       "        device='cuda:0', grad_fn=<SliceBackward0>),\n",
       " tensor([[-0.1516, -0.5622, -0.2321,  ..., -0.0000,  0.0000, -0.0899],\n",
       "         [ 0.1283,  0.4246,  0.1186,  ..., -0.9379, -0.7859,  1.6551],\n",
       "         [ 0.9275, -0.5030, -1.2906,  ..., -0.7969, -1.5502,  1.4657],\n",
       "         ...,\n",
       "         [ 0.4054,  0.5178,  0.0864,  ..., -0.5645,  0.0000, -0.0000],\n",
       "         [-4.1200,  2.0601, -0.0200,  ...,  2.7395, -2.4092,  0.0000],\n",
       "         [-2.3291,  1.0243,  0.3303,  ...,  0.6483, -0.0879,  2.2951]],\n",
       "        device='cuda:0', grad_fn=<SliceBackward0>),\n",
       " tensor([[-0.2537, -0.0954, -0.7542,  ...,  0.3950,  0.0000, -0.6942],\n",
       "         [ 0.0000, -0.3840, -0.0000,  ...,  0.0000, -0.1296,  0.1242],\n",
       "         [-0.2679, -0.6009, -0.7201,  ...,  0.1654, -0.8437,  0.0000],\n",
       "         ...,\n",
       "         [ 0.1345, -0.0000,  0.0000,  ...,  0.2151,  0.0000, -0.6239],\n",
       "         [ 0.3929, -0.5343,  0.6963,  ..., -0.0000,  0.7335, -0.0000],\n",
       "         [ 0.1968, -0.0000, -0.1579,  ..., -0.0000,  0.1135, -0.0000]],\n",
       "        device='cuda:0', grad_fn=<SliceBackward0>),\n",
       " tensor([[-0.0000, -0.9565, -0.9611,  ..., -0.6944,  0.7524, -0.5823],\n",
       "         [-0.7169, -0.0000, -1.1095,  ...,  0.0000, -0.2007, -0.0051],\n",
       "         [-0.3434, -0.6985, -1.1210,  ..., -0.0000,  0.6565, -0.7734],\n",
       "         ...,\n",
       "         [-1.3941, -0.6921, -2.3442,  ...,  0.1608, -0.3966, -0.5290],\n",
       "         [-1.3799, -0.2137, -2.2511,  ..., -0.8594, -0.3105, -1.4268],\n",
       "         [ 0.0192, -0.8643, -0.5951,  ...,  2.2818, -0.4467,  0.0956]],\n",
       "        device='cuda:0', grad_fn=<SliceBackward0>),\n",
       " tensor([[-0.0000,  0.2017, -0.2161,  ..., -0.0000,  1.7775, -0.7875],\n",
       "         [ 0.0652, -0.7045, -0.3291,  ..., -0.3913,  1.6299, -0.4526],\n",
       "         [ 0.5586, -1.9473, -0.0000,  ...,  0.4075,  2.6389, -0.3715],\n",
       "         ...,\n",
       "         [-0.0966,  0.1357,  0.4879,  ..., -0.8923,  0.0000, -0.0000],\n",
       "         [ 0.1849, -1.6513,  1.5542,  ...,  1.4852,  1.9986, -2.5318],\n",
       "         [ 0.0000, -1.6513,  1.5542,  ...,  1.4852,  1.9986, -2.5318]],\n",
       "        device='cuda:0', grad_fn=<SliceBackward0>),\n",
       " tensor([[-0.1218, -0.2169, -1.5869,  ..., -0.3622,  1.1298, -0.4075],\n",
       "         [ 0.7987,  0.1477, -1.7614,  ..., -0.0552,  0.8208,  0.2299],\n",
       "         [ 1.2298,  0.0000, -0.0000,  ...,  0.6223,  0.8873,  0.0908],\n",
       "         ...,\n",
       "         [-0.0488, -1.5931, -0.6635,  ...,  0.0000,  0.0000, -1.8034],\n",
       "         [-0.0000,  0.4883, -0.6106,  ..., -0.3825, -0.0000, -0.3573],\n",
       "         [-0.1921,  1.5229, -0.8669,  ..., -0.7858, -0.1467, -0.3705]],\n",
       "        device='cuda:0', grad_fn=<SliceBackward0>),\n",
       " tensor([[-0.0501, -0.5098, -0.0398,  ..., -0.0000,  0.5033, -0.9340],\n",
       "         [ 0.1954, -0.3598,  0.0909,  ..., -0.1649,  0.2229,  0.1794],\n",
       "         [ 0.2040, -0.0000, -0.0000,  ...,  0.0000, -0.0921,  0.0000],\n",
       "         ...,\n",
       "         [-0.0000,  0.8116,  0.0000,  ..., -0.1288, -1.5132,  0.8485],\n",
       "         [-0.2114,  0.2985,  0.0353,  ..., -0.1855, -0.2798, -0.2289],\n",
       "         [-0.0000, -0.1438,  0.1244,  ..., -0.0000,  0.6787, -0.7826]],\n",
       "        device='cuda:0', grad_fn=<SliceBackward0>),\n",
       " tensor([[-0.2078, -0.0000, -0.9389,  ..., -0.8590,  1.0953, -1.0294],\n",
       "         [ 0.0383,  0.0931,  0.5106,  ..., -0.1427,  0.6514,  0.0369],\n",
       "         [ 0.7001, -0.1486,  2.1092,  ..., -0.1127, -0.0000,  2.1259],\n",
       "         ...,\n",
       "         [ 0.7354,  0.0000, -0.9926,  ..., -1.2837,  1.2976,  1.0169],\n",
       "         [ 0.7271, -0.1354,  3.4884,  ...,  1.3684, -0.0000,  0.0000],\n",
       "         [ 0.0000, -0.4296,  0.8065,  ..., -0.6695,  0.0000, -0.2668]],\n",
       "        device='cuda:0', grad_fn=<SliceBackward0>),\n",
       " tensor([[ 1.0567,  0.8286,  0.1009,  ..., -0.2182,  0.6323, -0.6336],\n",
       "         [ 0.0000,  1.8249,  0.5913,  ...,  1.6196, -0.3324,  1.6144],\n",
       "         [ 0.0000,  0.0000,  1.4959,  ...,  2.6149, -0.0000,  1.2236],\n",
       "         ...,\n",
       "         [ 0.1984,  0.9226,  0.6364,  ...,  1.3322,  0.5102, -0.1955],\n",
       "         [ 2.7705, -0.0000,  0.8256,  ...,  1.5075, -0.9665,  2.5172],\n",
       "         [ 2.7597,  0.0000,  0.0000,  ...,  0.9558, -0.0000,  2.0706]],\n",
       "        device='cuda:0', grad_fn=<SliceBackward0>)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_rep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664baf91-74fc-4558-af2b-eb426afb4831",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f18e2db7-98cb-498e-ab88-96e85defb30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import math, random, sys\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from optparse import OptionParser\n",
    "from gnn_model import GNN, GNN_grover\n",
    "\n",
    "sys.path.append('./util/')\n",
    "\n",
    "from mol_tree import *\n",
    "from nnutils import *\n",
    "from datautils import *\n",
    "from motif_generation import *\n",
    "\n",
    "import rdkit\n",
    "\n",
    "# add for grover\n",
    "import wandb\n",
    "from grover.topology.mol_tree import *\n",
    "\n",
    "lg = rdkit.RDLogger.logger()\n",
    "lg.setLevel(rdkit.RDLogger.CRITICAL)\n",
    "# 치명적 오류가 발생되면 로그기록해라\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1a3e67-dbca-4349-b4e4-9c2253e18d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch implementation of pre-training of graph neural networks')\n",
    "parser.add_argument('--device', type=int, default=0,\n",
    "                    help='which gpu to use if any (default: 0)')\n",
    "parser.add_argument('--batch_size', type=int, default=32,\n",
    "                    help='input batch size for training (default: 32)')\n",
    "parser.add_argument('--epochs', type=int, default=100,\n",
    "                    help='number of epochs to train (default: 100)')\n",
    "parser.add_argument('--lr', type=float, default=0.001,\n",
    "                    help='learning rate (default: 0.001)')\n",
    "parser.add_argument('--decay', type=float, default=0,\n",
    "                    help='weight decay (default: 0)')\n",
    "parser.add_argument('--num_layer', type=int, default=5,\n",
    "                    help='number of GNN message passing layers (default: 5).')\n",
    "parser.add_argument('--emb_dim', type=int, default=300,\n",
    "                    help='embedding dimensions (default: 300)')\n",
    "parser.add_argument('--dropout_ratio', type=float, default=0.2,\n",
    "                    help='dropout ratio (default: 0.2)')\n",
    "parser.add_argument('--graph_pooling', type=str, default=\"mean\",\n",
    "                    help='graph level pooling (sum, mean, max, set2set, attention)')\n",
    "parser.add_argument('--JK', type=str, default=\"last\",\n",
    "                    help='how the node features across layers are combined. last, sum, max or concat')\n",
    "parser.add_argument('--dataset', type=str, default='./data/zinc/all.txt',\n",
    "                    help='root directory of dataset. For now, only classification.')\n",
    "parser.add_argument('--gnn_type', type=str, default=\"gin\")\n",
    "parser.add_argument('--input_model_file', type=str, default=\"\", help='filename to read the model (if there is any)')\n",
    "parser.add_argument('--output_model_file', type=str, default='./saved_model/motif_pretrain',\n",
    "                    help='filename to output the pre-trained model')\n",
    "parser.add_argument('--num_workers', type=int, default=0, help='number of workers for dataset loading')   #원래는 8이었음 오류로 0으로 바꿈\n",
    "parser.add_argument(\"--hidden_size\", type=int, default=300, help='hidden size')\n",
    "parser.add_argument(\"--latent_size\", type=int, default=56, help='latent size')\n",
    "parser.add_argument(\"--vocab\", type=str, default='./data/zinc/clique.txt', help='vocab path')\n",
    "parser.add_argument('--order', type=str, default=\"bfs\",\n",
    "                    help='motif tree generation order (bfs or dfs)')\n",
    "#for wandb\n",
    "parser.add_argument('--wandb', action='store_true', default=False, help='add wandb log')\n",
    "parser.add_argument('--wandb_name', type=str, default = 'MGSSL_Grover', help='wandb name')\n",
    "args = parser.parse_args(['--emb_dim', '1200', '--hidden_size', '1200', '--dataset', '../../data/merge_16/total.p'])\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "device = torch.device(\"cuda:\" + str(args.device)) if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(0)\n",
    "\n",
    "dataset = MoleculeDataset_grover(args.dataset)\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers, collate_fn=lambda x:x, drop_last=True)\n",
    "\n",
    "model = GNN(5, args.emb_dim, JK='last', drop_ratio=0.2, gnn_type='gin').to(device)\n",
    "if os.path.exists(args.input_model_file):\n",
    "    model.load_state_dict(torch.load(args.input_model_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b8fa56-0b5e-4969-9bea-1b10196179f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(args, model_list, loader, optimizer_list, device):\n",
    "    model, motif_model = model_list                             # 훈련간 사용 모델은 GNN모델과 motif모델이다.\n",
    "    optimizer_model, optimizer_motif = optimizer_list        # 옵티마이저도 둘에 대해 각각 사용하라.\n",
    "\n",
    "    model.eval()\t\t\t\t\t#모델, 모티프 모델 훈련!\n",
    "    motif_model.eval()\n",
    "    word_acc, topo_acc = 0, 0\t\t\t# 분자와 위상 정확도 변수 설정\n",
    "    for step, batch in enumerate(tqdm(loader, desc=\"Iteration\")):\t# 데이터로더에서 순회 진행바 표시형태로 순회해서 step과 batch대로 반복하자\n",
    "\n",
    "        batch_size = len(batch)\n",
    "\n",
    "        graph_batch = moltree_to_graph_data(batch)\t\t# 분자식을 파이토치 지오메트릭 패키지에서 요구되는 그래프 데이터 형태로 변경해서 배치단위로 저장   /datautils에 있음\n",
    "        #store graph object data in the process stage\t\n",
    "        batch_index = graph_batch.batch.numpy()\t\t\t# 배치내의 배치텐서를 넘파이로 인덱스에 넘겨라\n",
    "        graph_batch = graph_batch.to(device)\t\t\t# 그래프배치는 GPU로 되게\n",
    "        node_rep = model(graph_batch.x, graph_batch.edge_index, graph_batch.edge_attr)\t# GNN모델에 그래프(x, 엣지인덱스, 엣지의 특성) 투입\n",
    "        node_rep = group_node_rep(node_rep, batch_index, batch_size)\t\t\t# rep는 representation의 줄임말로 노드 표현을 의미\n",
    "        loss, wacc, tacc = motif_model(batch, node_rep)\t\t# motif모델에서 손실, motif정확도, 위상 정확도 출력\n",
    "\n",
    "        word_acc += wacc\n",
    "        topo_acc += tacc\t\t\t\t\t#위상 정확도\n",
    "        \n",
    "        if args.wandb :         \n",
    "            wandb.log({\"validation_loss\" : loss})\n",
    "\n",
    "        if (step+1) % 20 == 0:\n",
    "            word_acc = word_acc / 20 * 100\n",
    "            topo_acc = topo_acc / 20 * 100\n",
    "            print(\"Loss: %.1f, Word: %.2f, Topo: %.2f\" % (loss, word_acc, topo_acc))\n",
    "            word_acc, topo_acc = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e33ad596-4571-4fdc-bbe2-bb05e47f705b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 1234.556789\n",
    "epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01454449-47aa-4872-b319-b238beb648ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1234.5568\n"
     ]
    }
   ],
   "source": [
    "print(f'{data:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ffbbbe7-84f5-4631-b75a-e824a1494c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0001\n"
     ]
    }
   ],
   "source": [
    "print(f'{epoch:04d}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "263b4bf0-69ec-4adb-a5bc-e62af4ac83b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e-100>9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "caf2aba3-f0b6-4459-8fda-a5f3eada340a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, random, sys\n",
    "sys.path.append('./util/')\n",
    "from datautils import *\n",
    "dataset = MoleculeDataset_grover('../../data/merge_0/moltrees/0.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cac7aa4a-30cf-4389-8b4e-8bf753e84e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, val = train_test_split(dataset, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5057b360-e780-45f1-89fc-e1f73d58af12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1922f181-1179-4270-9da6-c4d8493828b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "900"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8995a7ab-ed57-49fd-8f75-6082f32cbf7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fec67db-70e3-4106-9c35-32b9ad01b127",
   "metadata": {},
   "source": [
    "# main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbe8eee1-ec80-400d-aec8-945e50bfb9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#python pretrain_grovermotif.py --dataset data/merge_0 --vocab data/merge_0/clique.txt --grover_dataset --output_path saved_model/grover\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import math, random, sys\n",
    "import numpy as np\n",
    "from optparse import OptionParser\n",
    "from gnn_model import GNN, GNN_grover\n",
    "\n",
    "sys.path.append('./util/')\n",
    "\n",
    "from mol_tree import *\n",
    "from nnutils import *\n",
    "from datautils import *\n",
    "from motif_generation import *\n",
    "\n",
    "import rdkit\n",
    "\n",
    "# add for grover\n",
    "import os, time\n",
    "import wandb\n",
    "from grover.topology.mol_tree import *\n",
    "from grover.topology.grover_datasets import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "lg = rdkit.RDLogger.logger()\n",
    "lg.setLevel(rdkit.RDLogger.CRITICAL)\n",
    "# 치명적 오류가 발생되면 로그기록해라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49378b95-1c62-4830-bd8f-0e6601e8d100",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_node_rep(node_rep, batch_index, batch_size):\n",
    "    group = []\n",
    "    count = 0\n",
    "    for i in range(batch_size):\n",
    "        num = sum(batch_index == i)\n",
    "        group.append(node_rep[count:count + num])\t\t# count += num번째 node의 표현을 그룹에 더해라\n",
    "        count += num\n",
    "    return group\t\t\t\t\t\t# 최종 그룹을 출력\n",
    "\n",
    "def train(args, model_list, loader, optimizer_list, device):\n",
    "    model, motif_model = model_list                             # 훈련간 사용 모델은 GNN모델과 motif모델이다.\n",
    "    optimizer_model, optimizer_motif = optimizer_list        # 옵티마이저도 둘에 대해 각각 사용하라.\n",
    "\n",
    "    model.train()\t\t\t\t\t#모델, 모티프 모델 훈련!\n",
    "    motif_model.train()\n",
    "    word_acc, topo_acc = 0, 0\t\t\t# 분자와 위상 정확도 변수 설정\n",
    "    for step, batch in enumerate(loader):\t# 데이터로더에서 순회 진행바 표시형태로 순회해서 step과 batch대로 반복하자\n",
    "\n",
    "        batch_size = len(batch)\n",
    "\n",
    "        graph_batch = moltree_to_graph_data(batch)\t\t# 분자식을 파이토치 지오메트릭 패키지에서 요구되는 그래프 데이터 형태로 변경해서 배치단위로 저장   /datautils에 있음\n",
    "        #store graph object data in the process stage\t\n",
    "        batch_index = graph_batch.batch.numpy()\t\t\t# 배치내의 배치텐서를 넘파이로 인덱스에 넘겨라\n",
    "        graph_batch = graph_batch.to(device)\t\t\t# 그래프배치는 GPU로 되게\n",
    "        node_rep = model(graph_batch.x, graph_batch.edge_index, graph_batch.edge_attr)\t# GNN모델에 그래프(x, 엣지인덱스, 엣지의 특성) 투입\n",
    "        node_rep = group_node_rep(node_rep, batch_index, batch_size)\t\t\t# rep는 representation의 줄임말로 노드 표현을 의미\n",
    "        loss, word_loss, topo_loss, wacc, tacc = motif_model(batch, node_rep)\t\t# motif모델에서 손실, motif정확도, 위상 정확도 출력\n",
    "\n",
    "        optimizer_model.zero_grad()\t\t\t\t#옵티마이저 0으로\n",
    "        optimizer_motif.zero_grad()\n",
    "        loss.backward()\t\t\t\t\t#손실 역전파\n",
    "\n",
    "        optimizer_model.step()\t\t\t\t#옵티마이저 시행\n",
    "        optimizer_motif.step()\n",
    "\n",
    "        word_acc += wacc\n",
    "        topo_acc += tacc\t\t\t\t\t#위상 정확도\n",
    "            \n",
    "    return loss, word_loss, topo_loss, word_acc*100, topo_acc*100\n",
    "\n",
    "def validation(args, model_list, loader, device):\n",
    "    model, motif_model = model_list                             # 훈련간 사용 모델은 GNN모델과 motif모델이다.\n",
    "\n",
    "    model.eval()\t\t\t\t\t#모델, 모티프 모델 훈련!\n",
    "    motif_model.eval()\n",
    "    word_acc, topo_acc = 0, 0\t\t\t# 분자와 위상 정확도 변수 설정\n",
    "    for step, batch in enumerate(loader):\t# 데이터로더에서 순회 진행바 표시형태로 순회해서 step과 batch대로 반복하자\n",
    "\n",
    "        batch_size = len(batch)\n",
    "\n",
    "        graph_batch = moltree_to_graph_data(batch)\t\t# 분자식을 파이토치 지오메트릭 패키지에서 요구되는 그래프 데이터 형태로 변경해서 배치단위로 저장   /datautils에 있음\n",
    "        #store graph object data in the process stage\t\n",
    "        batch_index = graph_batch.batch.numpy()\t\t\t# 배치내의 배치텐서를 넘파이로 인덱스에 넘겨라\n",
    "        graph_batch = graph_batch.to(device)\t\t\t# 그래프배치는 GPU로 되게\n",
    "        node_rep = model(graph_batch.x, graph_batch.edge_index, graph_batch.edge_attr)\t# GNN모델에 그래프(x, 엣지인덱스, 엣지의 특성) 투입\n",
    "        node_rep = group_node_rep(node_rep, batch_index, batch_size)\t\t\t# rep는 representation의 줄임말로 노드 표현을 의미\n",
    "        loss, word_loss, topo_loss, wacc, tacc = motif_model(batch, node_rep)\t\t# motif모델에서 손실, motif정확도, 위상 정확도 출력\n",
    "\n",
    "        word_acc += wacc\n",
    "        topo_acc += tacc\t\t\t\t\t#위상 정확도\n",
    "\n",
    "    return loss, word_loss, topo_loss, word_acc*100, topo_acc*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dca9c8a6-bfc0-4b1d-b018-a9733fe36453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreTrueAction(option_strings=['--grover_dataset'], dest='grover_dataset', nargs=0, const=True, default=False, type=None, choices=None, help='grover dataset mode', metavar=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch implementation of pre-training of graph neural networks')\n",
    "parser.add_argument('--device', type=int, default=0,\n",
    "                    help='which gpu to use if any (default: 0)')\n",
    "parser.add_argument('--batch_size', type=int, default=32,\n",
    "                    help='input batch size for training (default: 32)')\n",
    "parser.add_argument('--epochs', type=int, default=100,\n",
    "                    help='number of epochs to train (default: 100)')\n",
    "parser.add_argument('--lr', type=float, default=0.001,\n",
    "                    help='learning rate (default: 0.001)')\n",
    "parser.add_argument('--decay', type=float, default=0,\n",
    "                    help='weight decay (default: 0)')\n",
    "parser.add_argument('--num_layer', type=int, default=5,\n",
    "                    help='number of GNN message passing layers (default: 5).')\n",
    "parser.add_argument('--emb_dim', type=int, default=300,\n",
    "                    help='embedding dimensions (default: 300)')\n",
    "parser.add_argument('--dropout_ratio', type=float, default=0.2,\n",
    "                    help='dropout ratio (default: 0.2)')\n",
    "parser.add_argument('--graph_pooling', type=str, default=\"mean\",\n",
    "                    help='graph level pooling (sum, mean, max, set2set, attention)')\n",
    "parser.add_argument('--JK', type=str, default=\"last\",\n",
    "                    help='how the node features across layers are combined. last, sum, max or concat')\n",
    "parser.add_argument('--dataset', type=str, default='./data/zinc/all.txt',\n",
    "                    help='root directory of dataset. For now, only classification.')\n",
    "parser.add_argument('--gnn_type', type=str, default=\"gin\")\n",
    "parser.add_argument('--input_model_file', type=str, default=\"\", help='filename to read the model (if there is any)')\n",
    "parser.add_argument('--output_path', type=str, default='./saved_model/grover',\n",
    "                    help='filename to output the pre-trained model')\n",
    "parser.add_argument('--num_workers', type=int, default=0, help='number of workers for dataset loading')   #원래는 8이었음 오류로 0으로 바꿈\n",
    "parser.add_argument(\"--hidden_size\", type=int, default=300, help='hidden size')\n",
    "parser.add_argument(\"--latent_size\", type=int, default=56, help='latent size')\n",
    "parser.add_argument(\"--vocab\", type=str, default='./data/zinc/clique.txt', help='vocab path')\n",
    "parser.add_argument('--order', type=str, default=\"bfs\",\n",
    "                    help='motif tree generation order (bfs or dfs)')\n",
    "parser.add_argument('--seed', type=int, default=0,\n",
    "                    help='setting seed number')\n",
    "#for wandb\n",
    "parser.add_argument('--wandb', action='store_true', default=False, help='add wandb log')\n",
    "parser.add_argument('--wandb_name', type=str, default = 'MGSSL_Grover', help='wandb name')\n",
    "parser.add_argument('--grover_dataset', action='store_true', default=False, help='grover dataset mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d1318c51-eb35-42d9-8702-1e1a99dbcf17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(JK='last', batch_size=40, dataset='data/merge_0', decay=0, device=0, dropout_ratio=0.1, emb_dim=1200, epochs=100, gnn_type='gin', graph_pooling='mean', grover_dataset=True, hidden_size=1200, input_model_file='', latent_size=56, lr=0.001, num_layer=5, num_workers=0, order='dfs', output_path='output/grover', seed=0, vocab='data/merge_0/clique.txt', wandb=False, wandb_name='MGSSL_Grover')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = parser.parse_args(['--emb_dim', '1200', '--hidden_size', '1200', '--epochs', '100', '--batch_size', '40', '--grover_dataset',\n",
    "                          '--dropout_ratio', '0.1', '--vocab', 'data/merge_0/clique.txt', '--order', 'dfs', '--dataset', 'data/merge_0', \n",
    "                          '--output_path', 'output/grover'])\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5fa996c7-eb0e-41ea-90f7-20526193683f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data:\n",
      "Number of files: 20\n",
      "Number of samples: 20000\n",
      "Samples/file: 1000\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "device = torch.device(\"cuda:\" + str(args.device)) if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(args.seed)\n",
    "\n",
    "rank = 0\n",
    "num_replicas = 1\n",
    "if args.grover_dataset:\n",
    "    grover_data, sample_per_file = get_motif_data(args.dataset)\n",
    "    train_dataset, val_dataset, _ = split_data_grover(grover_data, sizes=(0.9,0.1,0), seed=0)\n",
    "    shared_dict = {}\n",
    "    GMC = GroverMotifCollator(shared_dict=shared_dict, args=args)\n",
    "    pre_load_data(train_dataset, rank = rank, num_replicas = num_replicas)\n",
    "    pre_load_data(val_dataset, rank = rank, num_replicas = num_replicas)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers, collate_fn=GMC)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers, collate_fn=GMC)\n",
    "\n",
    "else : \n",
    "    dataset = MoleculeDataset_grover(args.dataset)\n",
    "    train_dataset, val_dataset = train_test_split(dataset, test_size=0.5, random_state=42)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=args.num_workers, collate_fn=lambda x:x, drop_last=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=2, shuffle=True, num_workers=args.num_workers, collate_fn=lambda x:x, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e0b5405-870e-4daa-81c0-b704da443abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GNN(5, args.emb_dim, JK='last', drop_ratio=args.dropout_ratio, gnn_type='gin').to(device)\n",
    "if os.path.exists(args.input_model_file):\n",
    "    model.load_state_dict(torch.load(args.input_model_file))\n",
    "\n",
    "vocab = [x.strip(\"\\r\\n \") for x in open(args.vocab)]\n",
    "vocab = Vocab(vocab)\n",
    "motif_model = Motif_Generation_Grover(vocab, args.hidden_size, device, args.order).to(device)\n",
    "\n",
    "model_list = [model, motif_model]\n",
    "optimizer_model = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.decay)\n",
    "optimizer_motif = optim.Adam(motif_model.parameters(), lr=1e-3, weight_decay=args.decay)\n",
    "\n",
    "optimizer_list = [optimizer_model, optimizer_motif]\n",
    "\n",
    "if args.wandb :\n",
    "    wandb.init(project=args.wandb_name)\n",
    "    wandb.config = args\n",
    "    #wandb.watch(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4b268731-e7eb-4312-adde-e5e015aa6b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====epoch 1\n",
      "epoch : 0001 train_loss : 20.1973 train_node_loss : 17.1413 train_topo_loss : 3.0560 train_node_acc : 26300.13 train_topo_acc : 41731.20 train_time : 120.79s\n",
      "epoch : 0001 val_loss : 19.6792 val_node_loss : 15.5086 val_topo_loss : 4.1706 val_node_acc : 1612.44 val_topo_acc : 2380.62 val_tim : 4.58s\n",
      "====epoch 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-fee82350330b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtrain_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_node_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_topo_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_node_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_topo_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mtrain_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtrain_start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'epoch : {epoch:04d} train_loss : {train_loss:.4f} train_node_loss : {train_node_loss:.4f} train_topo_loss : {train_topo_loss:.4f} train_node_acc : {train_node_acc:.2f} train_topo_acc : {train_topo_acc:.2f} train_time : {train_end:.2f}s'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-ee7eb60ebd68>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, model_list, loader, optimizer_list, device)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mnode_rep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_attr\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# GNN모델에 그래프(x, 엣지인덱스, 엣지의 특성) 투입\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mnode_rep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup_node_rep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_rep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m                    \u001b[0;31m# rep는 representation의 줄임말로 노드 표현을 의미\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopo_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwacc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtacc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmotif_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_rep\u001b[0m\u001b[0;34m)\u001b[0m           \u001b[0;31m# motif모델에서 손실, motif정확도, 위상 정확도 출력\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0moptimizer_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                             \u001b[0;31m#옵티마이저 0으로\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/grover/MGSSL/pretrain/util/motif_generation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, mol_batch, node_rep)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mset_batch_nodeID\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmol_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mword_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopo_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopo_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmol_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_rep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtopo_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/grover/MGSSL/pretrain/util/dfs.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, mol_batch, node_rep)\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mpad_len\u001b[0m\u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                     \u001b[0mcur_h_nei\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_nei\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m                     \u001b[0mcur_h_nei\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpad_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                     \u001b[0mcur_h_nei\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_nei\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mMAX_NB\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#train start\n",
    "best_val_loss = 1e+10\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    print(\"====epoch \" + str(epoch))\n",
    "\n",
    "    #training\n",
    "    train_start = time.time()\n",
    "    train_loss, train_node_loss, train_topo_loss, train_node_acc, train_topo_acc = train(args, model_list, train_loader, optimizer_list, device)\n",
    "    train_end = time.time() - train_start\n",
    "    print(f'epoch : {epoch:04d} train_loss : {train_loss:.4f} train_node_loss : {train_node_loss:.4f} train_topo_loss : {train_topo_loss:.4f} train_node_acc : {train_node_acc:.2f} train_topo_acc : {train_topo_acc:.2f} train_time : {train_end:.2f}s')\n",
    "\n",
    "    #validation\n",
    "    val_start = time.time()\n",
    "    val_loss, val_node_loss, val_topo_loss, val_node_acc, val_topo_acc = validation(args, model_list, val_loader, device)\n",
    "    val_end = time.time() - val_start\n",
    "    print(f'epoch : {epoch:04d} val_loss : {val_loss:.4f} val_node_loss : {val_node_loss:.4f} val_topo_loss : {val_topo_loss:.4f} val_node_acc : {val_node_acc:.2f} val_topo_acc : {val_topo_acc:.2f} val_tim : {val_end:.2f}s')\n",
    "\n",
    "    if not os.path.exists(args.output_path):\n",
    "        os.mkdir(args.output_path)\n",
    "\n",
    "    if args.wandb :         \n",
    "        wandb.log({\"train_loss\" : train_loss, \"train_node_loss\" : train_node_loss, \"train_topo_loss\" : train_topo_loss, \n",
    "                   \"val_loss\" : val_loss, \"val_node_loss\" : val_node_loss, \"val_topo_loss\" : val_topo_loss})\n",
    "\n",
    "    torch.save(model.state_dict(), os.path.join(args.output_path, 'temp.pth'))\n",
    "    if best_val_loss > val_loss:\n",
    "        torch.save(model.state_dict(), os.path.join(args.output_path, f'best.pth'))\n",
    "    if epoch % 5 == 0:\n",
    "        torch.save(model.state_dict(), os.path.join(args.output_path, f'{epoch}.pth'))\n",
    "\n",
    "print('all train clear')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
