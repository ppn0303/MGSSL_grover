{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f58b7fd5-cdf7-42c0-94f0-49e43cad71b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#python pretrain_multi.py --emb_dim 300 --hidden_size 300 --epochs 100 --dropout_ratio 0.1 --dataset data/merge_0 --vocab data/merge_0/clique.txt --output_path saved_model/grover --batch_size 40 --order dfs --grover_dataset --multi\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import math, random, sys\n",
    "import numpy as np\n",
    "from optparse import OptionParser\n",
    "from gnn_model import GNN, GNN_grover\n",
    "\n",
    "sys.path.append('./util')\n",
    "sys.path.append('./grover')\n",
    "\n",
    "from util.mol_tree import *\n",
    "from util.nnutils import *\n",
    "from util.datautils import *\n",
    "from util.motif_generation import *\n",
    "\n",
    "import rdkit\n",
    "\n",
    "# add for grover\n",
    "import os, time\n",
    "import wandb\n",
    "from grover.topology.mol_tree import *\n",
    "from grover.topology.grover_datasets import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#for torch ddp\n",
    "import torch.multiprocessing as mp\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.distributed import init_process_group, destroy_process_group\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f75f579-98ff-4880-8679-fb6e1fa5f53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    # Training settings\n",
    "    parser = argparse.ArgumentParser(description='PyTorch implementation of pre-training of graph neural networks')\n",
    "    parser.add_argument('--batch_size', type=int, default=32,\n",
    "                        help='input batch size for training (default: 32)')\n",
    "    parser.add_argument('--epochs', type=int, default=100,\n",
    "                        help='number of epochs to train (default: 100)')\n",
    "    parser.add_argument('--lr', type=float, default=0.001,\n",
    "                        help='learning rate (default: 0.001)')\n",
    "    parser.add_argument('--decay', type=float, default=0,\n",
    "                        help='weight decay (default: 0)')\n",
    "    parser.add_argument('--num_layer', type=int, default=5,\n",
    "                        help='number of GNN message passing layers (default: 5).')\n",
    "    parser.add_argument('--emb_dim', type=int, default=300,\n",
    "                        help='embedding dimensions (default: 300)')\n",
    "    parser.add_argument('--dropout_ratio', type=float, default=0.1,\n",
    "                        help='dropout ratio (default: 0.1)')\n",
    "    parser.add_argument('--graph_pooling', type=str, default=\"sum\",\n",
    "                        help='graph level pooling (sum, mean, max, set2set, attention)')\n",
    "    parser.add_argument('--JK', type=str, default=\"last\",\n",
    "                        help='how the node features across layers are combined. last, sum, max or concat')\n",
    "    parser.add_argument('--dataset', type=str, default='./data/zinc/all.txt',\n",
    "                        help='root directory of dataset. For now, only classification.')\n",
    "    parser.add_argument('--gnn_type', type=str, default=\"gin\")\n",
    "    parser.add_argument('--input_model_file', type=str, default=\"\", help='filename to read the model (if there is any)')\n",
    "    parser.add_argument('--output_path', type=str, default='./saved_model/grover',\n",
    "                        help='filename to output the pre-trained model')\n",
    "    parser.add_argument('--num_workers', type=int, default=0, help='number of workers for dataset loading')  \n",
    "    parser.add_argument(\"--hidden_size\", type=int, default=300, help='hidden size')\n",
    "    parser.add_argument(\"--vocab\", type=str, default='./data/zinc/clique.txt', help='vocab path')\n",
    "    parser.add_argument('--order', type=str, default=\"dfs\",\n",
    "                        help='motif tree generation order (bfs or dfs)')\n",
    "    parser.add_argument('--seed', type=int, default=0,\n",
    "                        help='setting seed number')\n",
    "    #for wandb\n",
    "    parser.add_argument('--wandb', action='store_true', default=False, help='add wandb log')\n",
    "    parser.add_argument('--wandb_name', type=str, default = 'MGSSL_Grover', help='wandb name')\n",
    "    #for grovermode\n",
    "    parser.add_argument('--grover_dataset', action='store_true', default=False, help='grover dataset mode')\n",
    "    parser.add_argument('--multi', action='store_true', default=False, help='use multiprocess mode')\n",
    "    parser.add_argument('--rank', type=int, default=0)\n",
    "    parser.add_argument('--master_worker', action='store_true', default=True)\n",
    "    \n",
    "\n",
    "    args = parser.parse_args(['--dataset','data/zinc15_250K','--vocab','data/zinc15_250K/clique.txt','--grover_dataset'])\n",
    "    return args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a4defa2-3fcb-4c40-ab8d-499c35dc2bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_node_rep(node_rep, batch_index, batch_size):\n",
    "    group = []\n",
    "    count = 0\n",
    "    for i in range(batch_size):\n",
    "        num = sum(batch_index == i)\n",
    "        group.append(node_rep[count:count + num])\n",
    "        count += num\n",
    "    return group\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a671c768-5883-4013-96e5-b9a96ca50b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "emb_dim : 300, lr : 0.001, dropout : 0.1, batch_size : 32\n",
      "rank : 0\n",
      "Loading data:\n",
      "Number of files: 250\n",
      "Number of samples: 249624\n",
      "Samples/file: 1000\n",
      "train size : 225, val size : 25\n",
      "total 225000 data pre-loading\n",
      "total 24624 data pre-loading\n"
     ]
    }
   ],
   "source": [
    "args = parse_args()\n",
    "args.rank = int(os.environ[\"LOCAL_RANK\"]) if args.multi else 0\n",
    "args.master_worker = (args.rank == 0) if args.multi else True\n",
    "if args.master_worker : \n",
    "    if not os.path.exists(args.output_path):\n",
    "        os.mkdir(args.output_path)\n",
    "logger = create_logger('pretrain', args)\n",
    "debug = logger.debug\n",
    "info = logger.info\n",
    "\n",
    "#for distributed\n",
    "world_size = int(os.environ[\"WORLD_SIZE\"]) if args.multi else 1\n",
    "\n",
    "if args.master_worker : \n",
    "    info(f'emb_dim : {args.emb_dim}, lr : {args.lr}, dropout : {args.dropout_ratio}, batch_size : {args.batch_size}')\n",
    "info(f'rank : {args.rank}')\n",
    "\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "#device = torch.device(\"cuda:\" + str(args.device)) if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(args.seed)\n",
    "\n",
    "if args.grover_dataset:\n",
    "    grover_data, sample_per_file = get_motif_data(data_path = args.dataset, logger=logger)\n",
    "    train_dataset, val_dataset = split_data_grover(grover_data, sizes=(0.9,0.1,0), seed=args.seed, logger=logger)\n",
    "    shared_dict = {}\n",
    "    GMC = GroverMotifCollator(shared_dict=shared_dict, args=args)\n",
    "\n",
    "    pre_load_data(dataset=train_dataset, rank=args.rank, num_replicas=world_size, sample_per_file=sample_per_file, logger=logger)\n",
    "    pre_load_data(dataset=val_dataset, rank=args.rank, num_replicas=world_size, sample_per_file=sample_per_file, logger=logger)\n",
    "\n",
    "    train_sampler = DistributedSampler(dataset=train_dataset, num_replicas=world_size, rank=args.rank, shuffle=True, sample_per_file=sample_per_file)\n",
    "    val_sampler = DistributedSampler(dataset=val_dataset, num_replicas=world_size, rank=args.rank, shuffle=False, sample_per_file=sample_per_file)\n",
    "    train_sampler.set_epoch(args.epochs)\n",
    "    val_sampler.set_epoch(1)\n",
    "    idxs = val_sampler.get_indices()\n",
    "    for local_rank in idxs:\n",
    "        val_dataset.load_data(local_rank)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=False, num_workers=args.num_workers, collate_fn=GMC, sampler=train_sampler)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False, num_workers=args.num_workers, collate_fn=GMC, sampler=val_sampler)\n",
    "\n",
    "else : \n",
    "    dataset = MoleculeDataset_grover(args.dataset)\n",
    "    train_dataset, val_dataset = train_test_split(dataset, test_size=0.1, random_state=args.seed)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers, collate_fn=lambda x:x)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers, collate_fn=lambda x:x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28b4806f-db79-4ad8-9ef3-873549402ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "model = GNN_grover(5, args.emb_dim, JK='last', drop_ratio=args.dropout_ratio, gnn_type='gin').to(args.rank)        \n",
    "#model = DDP(model, device_ids = [args.rank])\n",
    "\n",
    "vocab = [x.strip(\"\\r\\n \") for x in open(args.vocab)]\n",
    "vocab = Vocab(vocab)\n",
    "motif_model = Motif_Generation_Grover(vocab, args.hidden_size, args.rank, args.order).to(args.rank)\n",
    "#motif_model = DDP(motif_model, device_ids = [args.rank])\n",
    "\n",
    "optimizer_model = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.decay)\n",
    "optimizer_motif = optim.Adam(motif_model.parameters(), lr=args.lr, weight_decay=args.decay)\n",
    "\n",
    "cp_path = f'{args.output_path}/temp.pth'\n",
    "if os.path.exists(cp_path):\n",
    "    resume_epoch, resume_batch, best_val_loss = load_cp(model, motif_model, optimizer_model, optimizer_motif, cp_path)\n",
    "    if args.master_worker:\n",
    "        info(f'load checkpoint : {resume_epoch}epoch, batch : {resume_batch}')\n",
    "    else : \n",
    "        debug(f'rank : {args.rank} load checkpoint : {resume_epoch}epoch, batch : {resume_batch}')\n",
    "else : \n",
    "    resume_epoch = 0\n",
    "    resume_batch = 0\n",
    "    best_val_loss = 1e+10\n",
    "\n",
    "model_list = [model, motif_model]\n",
    "optimizer_list = [optimizer_model, optimizer_motif]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac6e73ef-29a2-4bd0-a64f-40ef546c8892",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch_geometric/data/storage.py:309: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'x', 'edge_attr', 'edge_index'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n",
      "  \" to suppress this warning\")\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "full() received an invalid combination of arguments - got (tuple, int, device=NoneType), but expected one of:\n * (tuple of ints size, Number fill_value, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, Number fill_value, *, tuple of names names, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-7bbd4ec5de6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mgraph_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmoltree_to_grover_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mgraph_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/MGSSL/pretrain/util/datautils.py\u001b[0m in \u001b[0;36mmoltree_to_grover_data\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0mgraph_data_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmol_to_graph_data_obj_grover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m     \u001b[0mnew_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_data_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_data_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch_geometric/data/batch.py\u001b[0m in \u001b[0;36mfrom_data_list\u001b[0;34m(cls, data_list, follow_batch, exclude_keys)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0madd_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mfollow_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0mexclude_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         )\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch_geometric/data/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(cls, data_list, increment, add_batch, follow_batch, exclude_keys)\u001b[0m\n\u001b[1;32m    107\u001b[0m                 and stores[0].can_infer_num_nodes):\n\u001b[1;32m    108\u001b[0m             \u001b[0mrepeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_nodes\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstore\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstores\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0mout_store\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepeat_interleave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m             \u001b[0mout_store\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch_geometric/data/collate.py\u001b[0m in \u001b[0;36mrepeat_interleave\u001b[0;34m(repeats, device)\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m ) -> Tensor:\n\u001b[0;32m--> 252\u001b[0;31m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepeats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch_geometric/data/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m ) -> Tensor:\n\u001b[0;32m--> 252\u001b[0;31m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepeats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: full() received an invalid combination of arguments - got (tuple, int, device=NoneType), but expected one of:\n * (tuple of ints size, Number fill_value, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, Number fill_value, *, tuple of names names, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n"
     ]
    }
   ],
   "source": [
    "model, motif_model = model_list\n",
    "optimizer_model, optimizer_motif = optimizer_list\n",
    "\n",
    "model.train()\n",
    "motif_model.train()\n",
    "word_acc, topo_acc = 0, 0\n",
    "starting = False\n",
    "for step, batch in enumerate(train_loader):\n",
    "    if step==resume_batch:\n",
    "        starting=True\n",
    "    if starting : \n",
    "        batch_size = len(batch)\n",
    "\n",
    "        graph_batch = moltree_to_grover_data(batch)\n",
    "        batch_index = graph_batch.batch.numpy()\n",
    "        graph_batch = graph_batch.to(args.rank)\n",
    "        node_rep = model(graph_batch.x, graph_batch.edge_index, graph_batch.edge_attr)\n",
    "        node_rep = group_node_rep(node_rep, batch_index, batch_size)\n",
    "        loss, word_loss, topo_loss, word_acc, topo_acc = motif_model(batch, node_rep)\n",
    "\n",
    "        optimizer_model.zero_grad()\n",
    "        optimizer_motif.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer_model.step()\n",
    "        optimizer_motif.step()\n",
    "    if step==0:break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0d421576-541c-41b2-afea-a3de3a4da158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mol_to_graph_data_obj_grover(mol):\n",
    "    #mol = Chem.MolFromSmiles(mol)\n",
    "    hydrogen_donor = Chem.MolFromSmarts(\"[$([N;!H0;v3,v4&+1]),$([O,S;H1;+0]),n&H1&+0]\")\n",
    "    hydrogen_acceptor = Chem.MolFromSmarts(\n",
    "        \"[$([O,S;H1;v2;!$(*-*=[O,N,P,S])]),$([O,S;H0;v2]),$([O,S;-]),$([N;v3;!$(N-*=[O,N,P,S])]),\"\n",
    "        \"n&H0&+0,$([o,s;+0;!$([o,s]:n);!$([o,s]:c:n)])]\")\n",
    "    acidic = Chem.MolFromSmarts(\"[$([C,S](=[O,S,P])-[O;H1,-1])]\")\n",
    "    basic = Chem.MolFromSmarts(\n",
    "        \"[#7;+,$([N;H2&+0][$([C,a]);!$([C,a](=O))]),$([N;H1&+0]([$([C,a]);!$([C,a](=O))])[$([C,a]);\"\n",
    "        \"!$([C,a](=O))]),$([N;H0&+0]([C;!$(C(=O))])([C;!$(C(=O))])[C;!$(C(=O))])]\")\n",
    "\n",
    "    hydrogen_donor_match = sum(mol.GetSubstructMatches(hydrogen_donor), ())\n",
    "    hydrogen_acceptor_match = sum(mol.GetSubstructMatches(hydrogen_acceptor), ())\n",
    "    acidic_match = sum(mol.GetSubstructMatches(acidic), ())\n",
    "    basic_match = sum(mol.GetSubstructMatches(basic), ())\n",
    "    ring_info = mol.GetRingInfo()\n",
    "\n",
    "    n_atoms = mol.GetNumAtoms()\n",
    "    \n",
    "    f_atoms = []\n",
    "    for _, atom in enumerate(mol.GetAtoms()):\n",
    "        f_atoms.append(atom_features(atom, hydrogen_donor_match, hydrogen_acceptor_match, acidic_match, basic_match, ring_info))\n",
    "    f_atoms = [f_atoms[i] for i in range(n_atoms)]\n",
    "    \n",
    "    f_bonds = []\n",
    "    bond_list = []\n",
    "    for a1 in range(n_atoms):\n",
    "        for a2 in range(a1 + 1, n_atoms):\n",
    "            bond = mol.GetBondBetweenAtoms(a1, a2)\n",
    "\n",
    "            if bond is None:\n",
    "                continue\n",
    "\n",
    "            f_bond = bond_features(bond)\n",
    "\n",
    "            # Always treat the bond as directed.\n",
    "            f_bonds.append(f_atoms[a1] + f_bond)\n",
    "            bond_list.append([a1, a2])\n",
    "            f_bonds.append(f_atoms[a2] + f_bond)\n",
    "            bond_list.append([a2, a1])\n",
    "    \n",
    "#    data = [f_atoms, bond_list, f_bonds]\n",
    "    data = Data(x=torch.tensor(f_atoms), edge_index=torch.tensor(bond_list).T, edge_attr=torch.tensor(f_bonds))\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d6c8e31a-c292-4036-a2c3-9383aefb5fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_batch = Batch(graph_data_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1d5ebe87-80b2-42dd-aa39-daa411b15307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
       "        0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1201,\n",
       "        0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_data_batch[0].x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d5baead3-2152-4045-b7ce-432da16ebe68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  1,  2,  2,  3,  3,  4,  4,  5,  4,  6,  6,  7,  7,  8,  8,  9,\n",
       "          9, 10, 10, 11,  1, 12, 12, 13, 13, 14, 14, 15, 14, 16, 16, 17, 17, 18,\n",
       "         18, 19, 19, 20, 19, 21, 11,  7, 21, 16],\n",
       "        [ 1,  0,  2,  1,  3,  2,  4,  3,  5,  4,  6,  4,  7,  6,  8,  7,  9,  8,\n",
       "         10,  9, 11, 10, 12,  1, 13, 12, 14, 13, 15, 14, 16, 14, 17, 16, 18, 17,\n",
       "         19, 18, 20, 19, 21, 19,  7, 11, 16, 21]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_data_batch2[0].edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "34dba648-3ecf-435c-8b79-3bf7c577d2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data_batch = []\n",
    "for mol in batch:\n",
    "    graph_data_batch.append(mol_to_graph_data_obj_grover(mol.mol))\n",
    "new_batch = Batch().from_data_list(graph_data_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "12da4f19-75c1-4337-a6bd-ecce5ab53b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataDataBatch(x=[692, 171], edge_index=[2, 1470], edge_attr=[1470, 185], batch=[692], ptr=[33])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "999bda3e-4478-4060-90e8-d422a5635295",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (692x171 and 151x300)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-331bbfa675bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mgraph_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnode_rep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mnode_rep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup_node_rep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_rep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopo_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopo_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmotif_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_rep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/MGSSL/pretrain/gnn_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *argv)\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unmatched number of arguments.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0mh_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (692x171 and 151x300)"
     ]
    }
   ],
   "source": [
    "batch_index = new_batch.batch.numpy()\n",
    "graph_batch = new_batch.to(args.rank)\n",
    "node_rep = model(graph_batch.x, graph_batch.edge_index, graph_batch.edge_attr)\n",
    "node_rep = group_node_rep(node_rep, batch_index, batch_size)\n",
    "loss, word_loss, topo_loss, word_acc, topo_acc = motif_model(batch, node_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e6b6f87b-a487-4be7-b699-c2eff42e15d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data_batch2 = []\n",
    "for mol in batch:\n",
    "    graph_data_batch2.append(mol_to_graph_data_obj_simple(mol.mol))\n",
    "new_batch2 = Batch().from_data_list(graph_data_batch2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e4b4ae08-d478-44cb-af4b-45f65b15a233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataDataBatch(x=[692, 2], edge_index=[2, 1470], edge_attr=[1470, 2], batch=[692], ptr=[33])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_batch2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3632cc1d-d1a5-4c7a-8dbe-006040ff35ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
