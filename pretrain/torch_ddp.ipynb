{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "943b1eaa-39e4-4a96-ace9-2c0bfc6b3f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import math, random, sys\n",
    "import numpy as np\n",
    "from optparse import OptionParser\n",
    "from gnn_model import GNN, GNN_grover\n",
    "\n",
    "sys.path.append('./util/')\n",
    "\n",
    "from mol_tree import *\n",
    "from nnutils import *\n",
    "from datautils import *\n",
    "from motif_generation import *\n",
    "\n",
    "import rdkit\n",
    "\n",
    "# add for grover\n",
    "import os, time\n",
    "import wandb\n",
    "from grover.topology.mol_tree import *\n",
    "from grover.topology.grover_datasets import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#for torch ddp\n",
    "import torch.multiprocessing as mp\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.distributed import init_process_group, destroy_process_group\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2563da9d-b77c-4509-b998-cac496f672e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreTrueAction(option_strings=['--multi'], dest='multi', nargs=0, const=True, default=False, type=None, choices=None, help='use multiprocess mode', metavar=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch implementation of pre-training of graph neural networks')\n",
    "parser.add_argument('--batch_size', type=int, default=32,\n",
    "                    help='input batch size for training (default: 32)')\n",
    "parser.add_argument('--epochs', type=int, default=100,\n",
    "                    help='number of epochs to train (default: 100)')\n",
    "parser.add_argument('--lr', type=float, default=0.001,\n",
    "                    help='learning rate (default: 0.001)')\n",
    "parser.add_argument('--decay', type=float, default=0,\n",
    "                    help='weight decay (default: 0)')\n",
    "parser.add_argument('--num_layer', type=int, default=5,\n",
    "                    help='number of GNN message passing layers (default: 5).')\n",
    "parser.add_argument('--emb_dim', type=int, default=300,\n",
    "                    help='embedding dimensions (default: 300)')\n",
    "parser.add_argument('--dropout_ratio', type=float, default=0.2,\n",
    "                    help='dropout ratio (default: 0.2)')\n",
    "parser.add_argument('--graph_pooling', type=str, default=\"mean\",\n",
    "                    help='graph level pooling (sum, mean, max, set2set, attention)')\n",
    "parser.add_argument('--JK', type=str, default=\"last\",\n",
    "                    help='how the node features across layers are combined. last, sum, max or concat')\n",
    "parser.add_argument('--dataset', type=str, default='./data/zinc/all.txt',\n",
    "                    help='root directory of dataset. For now, only classification.')\n",
    "parser.add_argument('--gnn_type', type=str, default=\"gin\")\n",
    "parser.add_argument('--input_model_file', type=str, default=\"\", help='filename to read the model (if there is any)')\n",
    "parser.add_argument('--output_path', type=str, default='./saved_model/grover',\n",
    "                    help='filename to output the pre-trained model')\n",
    "parser.add_argument('--num_workers', type=int, default=0, help='number of workers for dataset loading')   #원래는 8이었음 오류로 0으로 바꿈\n",
    "parser.add_argument(\"--hidden_size\", type=int, default=300, help='hidden size')\n",
    "parser.add_argument(\"--vocab\", type=str, default='./data/zinc/clique.txt', help='vocab path')\n",
    "parser.add_argument('--order', type=str, default=\"dfs\",\n",
    "                    help='motif tree generation order (bfs or dfs)')\n",
    "parser.add_argument('--seed', type=int, default=0,\n",
    "                    help='setting seed number')\n",
    "#for wandb\n",
    "parser.add_argument('--wandb', action='store_true', default=False, help='add wandb log')\n",
    "parser.add_argument('--wandb_name', type=str, default = 'MGSSL_Grover', help='wandb name')\n",
    "#for grovermode\n",
    "parser.add_argument('--grover_dataset', action='store_true', default=False, help='grover dataset mode')\n",
    "parser.add_argument('--multi', action='store_true', default=False, help='use multiprocess mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d71fc92-c34c-4159-b73f-0b15b0567b66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(JK='last', batch_size=10, dataset='data/merge_0', decay=0, dropout_ratio=0.1, emb_dim=300, epochs=100, gnn_type='gin', graph_pooling='mean', grover_dataset=True, hidden_size=300, input_model_file='', lr=0.001, multi=True, num_layer=5, num_workers=0, order='dfs', output_path='output/grover', seed=0, vocab='data/merge_0/clique.txt', wandb=False, wandb_name='MGSSL_Grover')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = parser.parse_args(['--emb_dim', '300', '--hidden_size', '300', '--epochs', '100', '--batch_size', '10', '--grover_dataset',\n",
    "                          '--dropout_ratio', '0.1', '--vocab', 'data/merge_0/clique.txt', '--order', 'dfs', '--dataset', 'data/merge_0', \n",
    "                          '--output_path', 'output/grover','--multi'])\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e57f3055-606f-4538-8ec4-80df79bd3bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_node_rep(node_rep, batch_index, batch_size):\n",
    "    group = []\n",
    "    count = 0\n",
    "    for i in range(batch_size):\n",
    "        num = sum(batch_index == i)\n",
    "        group.append(node_rep[count:count + num])\t\t# count += num번째 node의 표현을 그룹에 더해라\n",
    "        count += num\n",
    "    return group\t\t\t\t\t\t# 최종 그룹을 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf1c0f20-1cef-42a3-8216-c879c3de90d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model_list, loader, optimizer_list, rank):\n",
    "    model, motif_model = model_list                             # 훈련간 사용 모델은 GNN모델과 motif모델이다.\n",
    "    optimizer_model, optimizer_motif = optimizer_list        # 옵티마이저도 둘에 대해 각각 사용하라.\n",
    "\n",
    "    model.train()\t\t\t\t\t#모델, 모티프 모델 훈련!\n",
    "    motif_model.train()\n",
    "    word_acc, topo_acc = 0, 0\t\t\t# 분자와 위상 정확도 변수 설정\n",
    "    for step, batch in enumerate(loader):\t# 데이터로더에서 순회 진행바 표시형태로 순회해서 step과 batch대로 반복하자\n",
    "\n",
    "        batch_size = len(batch)\n",
    "\n",
    "        graph_batch = moltree_to_graph_data(batch)\t\t# 분자식을 파이토치 지오메트릭 패키지에서 요구되는 그래프 데이터 형태로 변경해서 배치단위로 저장   /datautils에 있음\n",
    "        #store graph object data in the process stage\t\n",
    "        batch_index = graph_batch.batch.numpy()\t\t\t# 배치내의 배치텐서를 넘파이로 인덱스에 넘겨라\n",
    "        graph_batch = graph_batch.to(rank)\t\t\t# 그래프배치는 GPU로 되게\n",
    "        node_rep = model(graph_batch.x, graph_batch.edge_index, graph_batch.edge_attr)\t# GNN모델에 그래프(x, 엣지인덱스, 엣지의 특성) 투입\n",
    "        node_rep = group_node_rep(node_rep, batch_index, batch_size)\t\t\t# rep는 representation의 줄임말로 노드 표현을 의미\n",
    "        loss, word_loss, topo_loss, wacc, tacc = motif_model(batch, node_rep)\t\t# motif모델에서 손실, motif정확도, 위상 정확도 출력\n",
    "\n",
    "        optimizer_model.zero_grad()\t\t\t\t#옵티마이저 0으로\n",
    "        optimizer_motif.zero_grad()\n",
    "        loss.backward()\t\t\t\t\t#손실 역전파\n",
    "\n",
    "        optimizer_model.step()\t\t\t\t#옵티마이저 시행\n",
    "        optimizer_motif.step()\n",
    "\n",
    "        word_acc += wacc\n",
    "        topo_acc += tacc\t\t\t\t\t#위상 정확도\n",
    "            \n",
    "    return loss, word_loss, topo_loss, word_acc*100, topo_acc*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "592d4b3e-db3a-4e5d-aa87-07bd00c72cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(args, model_list, loader, rank):\n",
    "    model, motif_model = model_list                             # 훈련간 사용 모델은 GNN모델과 motif모델이다.\n",
    "\n",
    "    model.eval()\t\t\t\t\t#모델, 모티프 모델 훈련!\n",
    "    motif_model.eval()\n",
    "    word_acc, topo_acc = 0, 0\t\t\t# 분자와 위상 정확도 변수 설정\n",
    "    for step, batch in enumerate(loader):\t# 데이터로더에서 순회 진행바 표시형태로 순회해서 step과 batch대로 반복하자\n",
    "\n",
    "        batch_size = len(batch)\n",
    "\n",
    "        graph_batch = moltree_to_graph_data(batch)\t\t# 분자식을 파이토치 지오메트릭 패키지에서 요구되는 그래프 데이터 형태로 변경해서 배치단위로 저장   /datautils에 있음\n",
    "        #store graph object data in the process stage\t\n",
    "        batch_index = graph_batch.batch.numpy()\t\t\t# 배치내의 배치텐서를 넘파이로 인덱스에 넘겨라\n",
    "        graph_batch = graph_batch.to(rank)\t\t\t# 그래프배치는 GPU로 되게\n",
    "        node_rep = model(graph_batch.x, graph_batch.edge_index, graph_batch.edge_attr)\t# GNN모델에 그래프(x, 엣지인덱스, 엣지의 특성) 투입\n",
    "        node_rep = group_node_rep(node_rep, batch_index, batch_size)\t\t\t# rep는 representation의 줄임말로 노드 표현을 의미\n",
    "        loss, word_loss, topo_loss, wacc, tacc = motif_model(batch, node_rep)\t\t# motif모델에서 손실, motif정확도, 위상 정확도 출력\n",
    "\n",
    "        word_acc += wacc\n",
    "        topo_acc += tacc\t\t\t\t\t#위상 정확도\n",
    "\n",
    "    return loss, word_loss, topo_loss, word_acc*100, topo_acc*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f888bc3-857b-4170-b5af-312cfa0fa01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(rank, world_size):torch.manual_seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "#device = torch.device(\"cuda:\" + str(args.device)) if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(args.seed)\n",
    "ddp_setup(rank, world_size)\n",
    "if args.grover_dataset:\n",
    "    grover_data, sample_per_file = get_motif_data(args.dataset)\n",
    "    train_dataset, val_dataset, _ = split_data_grover(grover_data, sizes=(0.9,0.1,0), seed=args.seed)\n",
    "    shared_dict = {}\n",
    "    GMC = GroverMotifCollator(shared_dict=shared_dict, args=args)\n",
    "    pre_load_data(train_dataset, rank = rank, num_replicas = world_size)\n",
    "    pre_load_data(val_dataset, rank = rank, num_replicas = world_size)\n",
    "    #train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers, collate_fn=GMC)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=False, num_workers=args.num_workers, collate_fn=GMC, sampler=DistributedSampler(train_dataset))\n",
    "    val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False, num_workers=args.num_workers, collate_fn=GMC, sampler=DistributedSampler(val_dataset))\n",
    "\n",
    "else : \n",
    "    dataset = MoleculeDataset_grover(args.dataset)\n",
    "    train_dataset, val_dataset = train_test_split(dataset, test_size=0.1, random_state=args.seed)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers, collate_fn=lambda x:x)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers, collate_fn=lambda x:x)\n",
    "\n",
    "model = GNN(5, args.emb_dim, JK='last', drop_ratio=args.dropout_ratio, gnn_type='gin').to(rank)\n",
    "if os.path.exists(args.input_model_file):\n",
    "    model.load_state_dict(torch.load(args.input_model_file))\n",
    "\n",
    "model = DDP(model, device_ids = [rank])\n",
    "\n",
    "vocab = [x.strip(\"\\r\\n \") for x in open(args.vocab)]\n",
    "vocab = Vocab(vocab)\n",
    "motif_model = Motif_Generation_Grover(vocab, args.hidden_size, rank, args.order).to(rank)\n",
    "motif_model = DDP(motif_model, device_ids = [rank])\n",
    "\n",
    "model_list = [model, motif_model]\n",
    "optimizer_model = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.decay)\n",
    "optimizer_motif = optim.Adam(motif_model.parameters(), lr=args.lr, weight_decay=args.decay)\n",
    "\n",
    "optimizer_list = [optimizer_model, optimizer_motif]\n",
    "\n",
    "if args.wandb :\n",
    "    wandb.init(project=args.wandb_name)\n",
    "    wandb.config = args\n",
    "    #wandb.watch(model)\n",
    "\n",
    "#train start\n",
    "best_val_loss = 1e+10\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    print(\"====epoch \" + str(epoch))\n",
    "    #train_data.sampler.set_epoch(epoch)\n",
    "\n",
    "    #training\n",
    "    train_start = time.time()\n",
    "    train_loss, train_node_loss, train_topo_loss, train_node_acc, train_topo_acc = train(args, model_list, train_loader, optimizer_list, rank)\n",
    "    train_end = time.time() - train_start\n",
    "    print(f'epoch : {epoch:04d} train_loss : {train_loss:.4f} train_node_loss : {train_node_loss:.4f} train_topo_loss : {train_topo_loss:.4f} train_node_acc : {train_node_acc:.2f} train_topo_acc : {train_topo_acc:.2f} train_time : {train_end:.2f}s')\n",
    "\n",
    "    #validation\n",
    "    val_start = time.time()\n",
    "    val_loss, val_node_loss, val_topo_loss, val_node_acc, val_topo_acc = validation(args, model_list, val_loader, rank)\n",
    "    val_end = time.time() - val_start\n",
    "    print(f'epoch : {epoch:04d} val_loss : {val_loss:.4f} val_node_loss : {val_node_loss:.4f} val_topo_loss : {val_topo_loss:.4f} val_node_acc : {val_node_acc:.2f} val_topo_acc : {val_topo_acc:.2f} val_tim : {val_end:.2f}s')\n",
    "\n",
    "    if not os.path.exists(args.output_path):\n",
    "        os.mkdir(args.output_path)\n",
    "\n",
    "    if args.wandb :         \n",
    "        wandb.log({\"train_loss\" : train_loss, \"train_node_loss\" : train_node_loss, \"train_topo_loss\" : train_topo_loss, \n",
    "                   \"val_loss\" : val_loss, \"val_node_loss\" : val_node_loss, \"val_topo_loss\" : val_topo_loss})\n",
    "\n",
    "    #torch.save(model.state_dict(), os.path.join(args.output_path, 'temp.pth'))\n",
    "    if self.gpu_id==0:\n",
    "        torch.save(model.module.state_dict(), os.path.join(args.output_path, 'temp.pth'))\n",
    "        if best_val_loss > val_loss:\n",
    "            torch.save(model.state_dict(), os.path.join(args.output_path, f'best.pth'))\n",
    "        if epoch % 5 == 0:\n",
    "            torch.save(model.state_dict(), os.path.join(args.output_path, f'{epoch}.pth'))\n",
    "\n",
    "print('all train clear')\n",
    "destroy_process_group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "866b09a1-813b-4c20-bd17-ac5bc0a6cfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ddp_setup(rank: int, world_size: int):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    rank: Unique identifier of each process\n",
    "    world_size: Total number of processes\n",
    "    \"\"\"\n",
    "    os.environ[\"MASTER_ADDR\"] = \"0.0.0.0\"\n",
    "    os.environ[\"MASTER_PORT\"] = \"7731\"\n",
    "    init_process_group(backend=\"nccl\", rank=rank, world_size=world_size)\n",
    "    torch.cuda.set_device(rank)\n",
    "\n",
    "lg = rdkit.RDLogger.logger()\n",
    "lg.setLevel(rdkit.RDLogger.CRITICAL)\n",
    "# 치명적 오류가 발생되면 로그기록해라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "943710fb-c754-432f-b841-529af3279d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "world_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c456f7b7-8f76-4fe9-9047-445f2e489640",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'main' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-608c05edadfb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnprocs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'main' is not defined"
     ]
    }
   ],
   "source": [
    "rank = mp.spawn(main, args=(world_size, ), nprocs=world_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adaa5a4e-c3c7-49d2-9540-9b90c532a247",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "813e35f1-b996-44dc-897b-a9149fb14715",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-8c3bf90f8c7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'dtype'"
     ]
    }
   ],
   "source": [
    "time.time().dtype()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e66d0b6-f823-46f2-a1f0-c2d41db23b17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1690352053"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.int(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ac01bd8-4ad2-44cc-b63e-c8ff1f5e0ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import rdkit\n",
    "\n",
    "lg = rdkit.RDLogger.logger()\n",
    "lg.setLevel(rdkit.RDLogger.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "681e34ba-b7bd-4873-97b7-e60ea522d4fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<rdkit.RDLogger.logger at 0x7fe5b7bbd510>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f94d6036-cdf3-41aa-834a-53cd1e05453c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'logger' object has no attribute 'basicConfig'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-5ed1452a73eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlog_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"rdkit_logfile.log\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m lg.basicConfig(filename=log_file, filemode='w', level=lg.INFO,\n\u001b[0m\u001b[1;32m      3\u001b[0m                     format='%(message)s')\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'logger' object has no attribute 'basicConfig'"
     ]
    }
   ],
   "source": [
    "log_file = \"rdkit_logfile.log\"\n",
    "lg.basicConfig(filename=log_file, filemode='w', level=lg.INFO,\n",
    "                    format='%(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "faaa2d37-a16b-4e46-836f-5fd6948032fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging, os\n",
    "from rdkit import RDLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8be1d5e-456b-4b69-9498-16dfe08df7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_logger(name, save_dir, quiet = False):\n",
    "    logger = logging.getLogger(name)\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    logger.propagate = False\n",
    "\n",
    "    # Set logger depending on desired verbosity\n",
    "    ch = logging.StreamHandler()\n",
    "    if quiet:\n",
    "        ch.setLevel(logging.INFO)\n",
    "    else:\n",
    "        ch.setLevel(logging.DEBUG)\n",
    "    logger.addHandler(ch)\n",
    "\n",
    "    if save_dir is not None:\n",
    "        os.makedirs(save_dir)\n",
    "        fh_v = logging.FileHandler(os.path.join(save_dir, 'verbose.log'))\n",
    "        fh_v.setLevel(logging.DEBUG)\n",
    "        fh_q = logging.FileHandler(os.path.join(save_dir, 'quiet.log'))\n",
    "        fh_q.setLevel(logging.INFO)\n",
    "\n",
    "        logger.addHandler(fh_v)\n",
    "        logger.addHandler(fh_q)\n",
    "\n",
    "    return logger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "909a33c2-645f-4d87-af65-b02b1e7495e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_logger = create_logger('test', 'log_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d12604a-513e-4eee-b9f9-808506d8e35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = new_logger.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0159fb80-02d9-45a5-9c7f-f2a134d499dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test\n",
      "test\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "info('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bb2af9-ad66-48fc-a33b-8a242bb9b1b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
